{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9uj1DjDN0IG",
        "ihFDvO5PLFSA",
        "Lu3rcbcdLosm",
        "5V79A9rcLyUE",
        "UakDqoK3JGGz",
        "jEtgHMvInoq5",
        "OTePDMH1sqTS",
        "Goc-GxOyqVbK",
        "ibtZ5mP-sbe0",
        "tSvkTTA7wNCI",
        "tom68FwRCQvf",
        "NwNcxXlhCaca",
        "K0XlyFm4oPdy",
        "ajW1GktnLHC8",
        "T8xZKmRysyBL",
        "rhoEDjw6MowO",
        "FSs--RTiN7V-",
        "nOrxl3m2Ytjk",
        "YoJNXwEnYynF",
        "rzq5I4qhN-4b"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NNDL HomeWork 4\n",
        "This is the fourth homework of NNDL course about RNNs  \n",
        "by **Ali Ranjbari**"
      ],
      "metadata": {
        "id": "ZvCclESuK_TV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and installs"
      ],
      "metadata": {
        "id": "c9uj1DjDN0IG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics"
      ],
      "metadata": {
        "id": "qenyfs5ALX9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a261bdf-d992-415e-da27-f5c4322c300f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 30 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 51 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 61 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 71 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 81 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 92 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 102 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 112 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 122 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 133 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 143 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 153 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 163 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 174 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 184 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 194 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 204 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 215 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 225 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 235 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 245 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 256 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 266 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 276 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 286 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 296 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 307 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 317 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 327 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 337 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 348 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 358 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 368 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 378 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 389 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 399 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 409 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 419 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 430 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 440 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 450 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 460 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 471 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 481 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 491 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 501 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 512 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 512 kB 15.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from math import ceil\n",
        "import nltk\n",
        "from torchmetrics import (\n",
        "  R2Score,\n",
        "  MeanAbsoluteError,\n",
        "  MeanSquaredError,\n",
        ")\n",
        "from torchmetrics.functional.classification import (\n",
        "    multiclass_accuracy,\n",
        "    multiclass_precision,\n",
        "    multiclass_f1_score,\n",
        "    multiclass_recall\n",
        ")\n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.data import get_tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0AA9t697LPWu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'device is {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4MTGoJzRgEc",
        "outputId": "c933a6f0-8330-4960-a0a5-7bc10ea45f29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device is cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1) Air Pollution Detection"
      ],
      "metadata": {
        "id": "ihFDvO5PLFSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Loading the data"
      ],
      "metadata": {
        "id": "Lu3rcbcdLosm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWaJolmSN9dJ",
        "outputId": "3e26e697-7cf2-497c-efc4-1a4a0de87928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp drive/MyDrive/Datasets/NNDL_HW04/* .\n",
        "!unzip PRSA2017_Data_20130301-20170228.zip\n",
        "%cd PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/\n",
        "%ls ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHB8yxbWOHMD",
        "outputId": "e64dbcf8-683f-4360-f31c-b34c46c913ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  PRSA2017_Data_20130301-20170228.zip\n",
            "   creating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/\n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Aotizhongxin_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Changping_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Dingling_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Dongsi_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Guanyuan_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Gucheng_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Huairou_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Nongzhanguan_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Shunyi_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Tiantan_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Wanliu_20130301-20170228.csv  \n",
            "  inflating: PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Wanshouxigong_20130301-20170228.csv  \n",
            "/content/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228\n",
            "PRSA_Data_Aotizhongxin_20130301-20170228.csv\n",
            "PRSA_Data_Changping_20130301-20170228.csv\n",
            "PRSA_Data_Dingling_20130301-20170228.csv\n",
            "PRSA_Data_Dongsi_20130301-20170228.csv\n",
            "PRSA_Data_Guanyuan_20130301-20170228.csv\n",
            "PRSA_Data_Gucheng_20130301-20170228.csv\n",
            "PRSA_Data_Huairou_20130301-20170228.csv\n",
            "PRSA_Data_Nongzhanguan_20130301-20170228.csv\n",
            "PRSA_Data_Shunyi_20130301-20170228.csv\n",
            "PRSA_Data_Tiantan_20130301-20170228.csv\n",
            "PRSA_Data_Wanliu_20130301-20170228.csv\n",
            "PRSA_Data_Wanshouxigong_20130301-20170228.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./PRSA_Data_Aotizhongxin_20130301-20170228.csv\")"
      ],
      "metadata": {
        "id": "llsR4lzLRMud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = os.listdir()\n",
        "# df = pd.DataFrame()\n",
        "for name in names:\n",
        "  if \"Aotizhongxin\" in name:\n",
        "    continue\n",
        "\n",
        "  df_temp = pd.read_csv(name)\n",
        "  station_name = name.split(\"_\")[2][0:4]\n",
        "  df[f\"PM2.5_{station_name}\"] = df_temp[\"PM2.5\"]\n",
        "\n",
        "df = df.drop(\"station\", axis=1)"
      ],
      "metadata": {
        "id": "rR-5Zn0mRgic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_PM = df.copy()\n",
        "for c in df_PM.columns:\n",
        "  if 'PM2.5' not in c:\n",
        "    df_PM.drop(c, axis=1, inplace=True)\n",
        "    print(f\"droped {c}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoVZh8gUOqsG",
        "outputId": "d555fd15-06fc-4ab9-c270-fc82d311d0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "droped No\n",
            "droped year\n",
            "droped month\n",
            "droped day\n",
            "droped hour\n",
            "droped PM10\n",
            "droped SO2\n",
            "droped NO2\n",
            "droped CO\n",
            "droped O3\n",
            "droped TEMP\n",
            "droped PRES\n",
            "droped DEWP\n",
            "droped RAIN\n",
            "droped wd\n",
            "droped WSPM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Preprocessing"
      ],
      "metadata": {
        "id": "5V79A9rcLyUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Missing value\n",
        "Handling missing values with Linear interpolation method"
      ],
      "metadata": {
        "id": "UakDqoK3JGGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.interpolate(method=\"linear\", limit_direction = \"forward\")"
      ],
      "metadata": {
        "id": "Cti6rWsfl3Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_PM = df_PM.interpolate(method=\"linear\", limit_direction = \"forward\")"
      ],
      "metadata": {
        "id": "bUw3_3nRrpl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Encoding Categorical Variable\n"
      ],
      "metadata": {
        "id": "jEtgHMvInoq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = [\"N\", \"NNE\", \"NE\", \"ENE\", \"E\", \"ESE\", \"SE\", \"SSE\", \"S\", \"SSW\", \"SW\", \"WSW\", \"W\", \"WNW\", \"NW\", \"NNW\", \"N\"]\n",
        "degrees = [ i*22.5 for i in range(17)]"
      ],
      "metadata": {
        "id": "o3owGWCznBM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['wd'].replace(values, degrees, inplace=True)"
      ],
      "metadata": {
        "id": "N3YHEy3Ipyxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"wd\" column still has NaN values so after converting to degree we perform LI\n",
        "df = df.interpolate(method=\"linear\", limit_direction = \"forward\")"
      ],
      "metadata": {
        "id": "IvVHwDMdp6CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Normalization\n",
        "Normalize using min-max normalization"
      ],
      "metadata": {
        "id": "OTePDMH1sqTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df.columns:\n",
        "  df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())"
      ],
      "metadata": {
        "id": "JYuOlvsQsugw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df_PM.columns:\n",
        "  df_PM[column] = (df_PM[column] - df_PM[column].min()) / (df_PM[column].max() - df_PM[column].min())"
      ],
      "metadata": {
        "id": "d3-xyxWLsuox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4 Pearson Correlation\n",
        "Just for PM columns"
      ],
      "metadata": {
        "id": "Goc-GxOyqVbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df_PM.corr(method=\"pearson\")\n",
        "sns.heatmap(corr)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "uo4LIL0Fq9hE",
        "outputId": "b985e7ee-7de1-44e8-89fc-c9a0617cccf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.5 Feature selection"
      ],
      "metadata": {
        "id": "ibtZ5mP-sbe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# features is this columns and all column that have PM in it\n",
        "features = [\"CO\", \"TEMP\", \"PRES\", \"DEWP\", \"RAIN\", \"wd\", \"WSPM\"]\n",
        "for c in df.columns:\n",
        "  if c in features or 'PM' in c:\n",
        "    continue\n",
        "  df = df.drop(c, axis=1)"
      ],
      "metadata": {
        "id": "LX3txv7uuo5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now save the table as csv with name `PRSA_Data_features.csv`"
      ],
      "metadata": {
        "id": "dkSKCOM4ve6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"../../PRSA_Data_features.csv\")"
      ],
      "metadata": {
        "id": "BDZ8r9IUupvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.5 Supervised dataset\n",
        "Convert data to supervised and ready for training  \n",
        "We built two dataset 1 and 7 days lag  "
      ],
      "metadata": {
        "id": "tSvkTTA7wNCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_lag1 = []\n",
        "y_lag1 = []\n",
        "df_np = df.to_numpy()\n",
        "for i in range(0, df.shape[0]-24):\n",
        "  X_lag1.append(\n",
        "      np.expand_dims(df_np[i:i+24, :], axis=0))\n",
        "  y_lag1.append(\n",
        "      np.expand_dims(df_np[i+24, 0], axis=0))\n",
        "  \n",
        "# concatination\n",
        "X1 = np.concatenate(X_lag1)\n",
        "y1 = np.concatenate(y_lag1)\n",
        "\n",
        "# train test split (80-20)\n",
        "train_size = ceil(X1.shape[0] * 0.8)\n",
        "X1_train = X1[0:train_size, :, :]\n",
        "X1_test = X1[train_size:, :, :]\n",
        "y1_train = y1[0:train_size]\n",
        "y1_test = y1[train_size:]"
      ],
      "metadata": {
        "id": "jDYmaLLawUeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_lag7 = []\n",
        "y_lag7 = []\n",
        "df_np = df.to_numpy()\n",
        "step = (24 * 7) \n",
        "for i in range(0, df.shape[0]-step):\n",
        "  X_lag7.append(\n",
        "      np.expand_dims(df_np[i:i+step, :], axis=0))\n",
        "  y_lag7.append(\n",
        "      np.expand_dims(df_np[i+step, 0], axis=0))\n",
        "\n",
        "# concatination\n",
        "X7 = np.concatenate(X_lag7)\n",
        "y7 = np.concatenate(y_lag7)\n",
        "\n",
        "# train test split (80-20)\n",
        "train_size = ceil(X7.shape[0] * 0.8)\n",
        "X7_train = X7[0:train_size,:,:]\n",
        "X7_test = X7[train_size:, :, :]\n",
        "y7_train = y7[0:train_size]\n",
        "y7_test = y7[train_size:]"
      ],
      "metadata": {
        "id": "vuo7GtJ47NKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PollutionDataset(Dataset):\n",
        "  def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
        "    super().__init__()\n",
        "    self.input = torch.tensor(X, dtype=torch.float)\n",
        "    self.target = torch.tensor(y, dtype=torch.float)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input[idx], self.target[idx]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.input.shape[0]"
      ],
      "metadata": {
        "id": "6cxm1hB_HXa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train1_dataset = PollutionDataset(X1_train, y1_train) \n",
        "test1_dataset = PollutionDataset(X1_test, y1_test) \n",
        "train7_dataset = PollutionDataset(X7_train, y7_train) \n",
        "test7_dataset = PollutionDataset(X7_test, y7_test) "
      ],
      "metadata": {
        "id": "RpVD_f3GI6Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Build the model "
      ],
      "metadata": {
        "id": "tom68FwRCQvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_LSTM(nn.Module):\n",
        "\n",
        "  def __init__(self, seq_size: int):\n",
        "    super().__init__()\n",
        "\n",
        "    # conv self\n",
        "    self.conv1 = nn.Conv1d(seq_size, 64, 3, padding=\"same\",\n",
        "                           padding_mode='zeros')              # 20 -> 20\n",
        "    self.norm1 = nn.BatchNorm1d(64)\n",
        "    self.conv2 = nn.Conv1d(64, 64, 3, paddin3g=\"same\",\n",
        "                           padding_mode='zeros')              # 20 -> 20\n",
        "    self.norm2 = nn.BatchNorm1d(64)\n",
        "    self.conv3 = nn.Conv1d(64, 32, 3, padding=\"same\",\n",
        "                           padding_mode='zeros')              # 20 -> 20 \n",
        "    self.max_pool = nn.MaxPool1d(3)                           # 20 -> 6\n",
        "\n",
        "\n",
        "    # lstm layer\n",
        "    self.lstm1 = nn.LSTM(input_size=6, hidden_size=100, batch_first=True)\n",
        "    self.lstm2 = nn.LSTM(input_size=100, hidden_size=50, batch_first=True)\n",
        "    self.drop02 = nn.Dropout1d(0.2)\n",
        "    self.drop03 = nn.Dropout1d(0.3)\n",
        "    \n",
        "    # output layer\n",
        "    self.fc = nn.Linear(50*32, 1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # conv layer\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.norm1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.norm2(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.max_pool(x)\n",
        "\n",
        "    # lstm layer\n",
        "    x = self.drop02(self.lstm1(x)[0])\n",
        "    x = self.drop03(self.lstm2(x)[0])\n",
        "\n",
        "\n",
        "    x = x.reshape((-1, 50*32))\n",
        "    # output layer\n",
        "    x = F.relu(self.fc(x))\n",
        "    x = x.squeeze()\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "Qr-PZPmICink"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Train"
      ],
      "metadata": {
        "id": "NwNcxXlhCaca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = CNN_LSTM(seq_size=24)\n",
        "model1.to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model1.parameters(),\n",
        "                                lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "mse_metric = MeanSquaredError().to(device)\n",
        "mae_metric = MeanAbsoluteError().to(device)\n",
        "r2_metric = R2Score().to(device)\n",
        "train1_dataloader = DataLoader(train1_dataset,\n",
        "                              batch_size = 32, shuffle=True)"
      ],
      "metadata": {
        "id": "spu1UD4URZ35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning loop\n",
        "r2s = []\n",
        "maes = []\n",
        "rmses = []\n",
        "EPOCHS = 50\n",
        "\n",
        "n_total = len(train1_dataloader)\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  targets = []\n",
        "  print(f\"*************** Epoch {epoch} ***************\")\n",
        "  print(\" [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \")\n",
        "  for i, (inputs, target) in enumerate(train1_dataloader):\n",
        "    \n",
        "    inputs = inputs.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    predicted = model1(inputs)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(predicted, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "    if (i+1) % 300 == 0:\n",
        "      with torch.no_grad():\n",
        "        r2 = r2_metric(predicted, target)\n",
        "        mae = mae_metric(predicted, target)\n",
        "        mse = mse_metric(predicted, target)\n",
        "        print(f\"[{i+1}/{n_total}]  {loss.item():.3f}   {r2.item():.3f}   {mae.item():.3f}   {torch.sqrt(mse).item():.3f}\")\n",
        "\n",
        "  r2s.append(r2.item())\n",
        "  maes.append(mae.item())\n",
        "  rmses.append(torch.sqrt(mse).item())\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw9XIZLJYQIG",
        "outputId": "f4b0836a-5678-45d5-b864-d312a0b3bb84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************** Epoch 1 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.898   0.026   0.033\n",
            "[600/876]  0.001   0.819   0.027   0.033\n",
            "*************** Epoch 2 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.889   0.023   0.037\n",
            "[600/876]  0.001   0.872   0.018   0.024\n",
            "*************** Epoch 3 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.920   0.020   0.026\n",
            "[600/876]  0.000   0.916   0.013   0.017\n",
            "*************** Epoch 4 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.922   0.023   0.033\n",
            "[600/876]  0.000   0.971   0.013   0.019\n",
            "*************** Epoch 5 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.966   0.016   0.020\n",
            "[600/876]  0.001   0.783   0.020   0.034\n",
            "*************** Epoch 6 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.953   0.013   0.016\n",
            "[600/876]  0.000   0.939   0.014   0.019\n",
            "*************** Epoch 7 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.866   0.014   0.020\n",
            "[600/876]  0.000   0.947   0.014   0.021\n",
            "*************** Epoch 8 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.924   0.020   0.027\n",
            "[600/876]  0.001   0.879   0.017   0.029\n",
            "*************** Epoch 9 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.965   0.014   0.017\n",
            "[600/876]  0.000   0.960   0.015   0.020\n",
            "*************** Epoch 10 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.003   0.587   0.023   0.052\n",
            "[600/876]  0.001   0.949   0.018   0.025\n",
            "*************** Epoch 11 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.872   0.018   0.024\n",
            "[600/876]  0.001   0.896   0.021   0.032\n",
            "*************** Epoch 12 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.909   0.016   0.020\n",
            "[600/876]  0.001   0.876   0.016   0.023\n",
            "*************** Epoch 13 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.822   0.015   0.020\n",
            "[600/876]  0.002   0.728   0.023   0.041\n",
            "*************** Epoch 14 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.970   0.015   0.020\n",
            "[600/876]  0.001   0.863   0.023   0.035\n",
            "*************** Epoch 15 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.949   0.014   0.020\n",
            "[600/876]  0.001   0.932   0.022   0.032\n",
            "*************** Epoch 16 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.963   0.018   0.025\n",
            "[600/876]  0.001   0.790   0.017   0.026\n",
            "*************** Epoch 17 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.965   0.013   0.019\n",
            "[600/876]  0.001   0.948   0.019   0.025\n",
            "*************** Epoch 18 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.955   0.018   0.026\n",
            "[600/876]  0.000   0.892   0.013   0.016\n",
            "*************** Epoch 19 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.916   0.016   0.021\n",
            "[600/876]  0.001   0.919   0.020   0.028\n",
            "*************** Epoch 20 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.803   0.024   0.031\n",
            "[600/876]  0.001   0.930   0.019   0.025\n",
            "*************** Epoch 21 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.903   0.021   0.030\n",
            "[600/876]  0.001   0.951   0.016   0.023\n",
            "*************** Epoch 22 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.918   0.016   0.019\n",
            "[600/876]  0.000   0.945   0.014   0.019\n",
            "*************** Epoch 23 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.946   0.016   0.025\n",
            "[600/876]  0.008   0.399   0.035   0.089\n",
            "*************** Epoch 24 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.935   0.014   0.018\n",
            "[600/876]  0.001   0.939   0.020   0.029\n",
            "*************** Epoch 25 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.940   0.016   0.021\n",
            "[600/876]  0.000   0.976   0.011   0.014\n",
            "*************** Epoch 26 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.863   0.020   0.028\n",
            "[600/876]  0.001   0.873   0.017   0.025\n",
            "*************** Epoch 27 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.944   0.022   0.027\n",
            "[600/876]  0.001   0.898   0.020   0.025\n",
            "*************** Epoch 28 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.002   0.787   0.021   0.041\n",
            "[600/876]  0.001   0.893   0.022   0.030\n",
            "*************** Epoch 29 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.927   0.016   0.021\n",
            "[600/876]  0.000   0.932   0.014   0.018\n",
            "*************** Epoch 30 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.861   0.018   0.024\n",
            "[600/876]  0.000   0.927   0.013   0.019\n",
            "*************** Epoch 31 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.891   0.022   0.025\n",
            "[600/876]  0.001   0.913   0.016   0.024\n",
            "*************** Epoch 32 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.969   0.012   0.016\n",
            "[600/876]  0.000   0.946   0.016   0.019\n",
            "*************** Epoch 33 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.955   0.019   0.024\n",
            "[600/876]  0.000   0.966   0.012   0.014\n",
            "*************** Epoch 34 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.948   0.015   0.017\n",
            "[600/876]  0.000   0.935   0.016   0.021\n",
            "*************** Epoch 35 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.848   0.020   0.029\n",
            "[600/876]  0.001   0.890   0.018   0.033\n",
            "*************** Epoch 36 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.878   0.019   0.029\n",
            "[600/876]  0.001   0.965   0.018   0.023\n",
            "*************** Epoch 37 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.879   0.019   0.029\n",
            "[600/876]  0.002   0.847   0.019   0.043\n",
            "*************** Epoch 38 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.959   0.016   0.023\n",
            "[600/876]  0.001   0.947   0.017   0.028\n",
            "*************** Epoch 39 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.942   0.016   0.020\n",
            "[600/876]  0.000   0.969   0.013   0.018\n",
            "*************** Epoch 40 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.933   0.016   0.022\n",
            "[600/876]  0.000   0.938   0.015   0.018\n",
            "*************** Epoch 41 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.952   0.014   0.016\n",
            "[600/876]  0.001   0.958   0.017   0.023\n",
            "*************** Epoch 42 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.920   0.014   0.022\n",
            "[600/876]  0.001   0.923   0.021   0.033\n",
            "*************** Epoch 43 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.852   0.018   0.025\n",
            "[600/876]  0.000   0.943   0.016   0.021\n",
            "*************** Epoch 44 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.776   0.017   0.026\n",
            "[600/876]  0.000   0.966   0.014   0.019\n",
            "*************** Epoch 45 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.887   0.015   0.019\n",
            "[600/876]  0.000   0.960   0.011   0.014\n",
            "*************** Epoch 46 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.925   0.019   0.030\n",
            "[600/876]  0.000   0.950   0.015   0.020\n",
            "*************** Epoch 47 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.888   0.016   0.020\n",
            "[600/876]  0.001   0.845   0.025   0.038\n",
            "*************** Epoch 48 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.001   0.945   0.018   0.023\n",
            "[600/876]  0.000   0.954   0.013   0.018\n",
            "*************** Epoch 49 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.947   0.013   0.020\n",
            "[600/876]  0.001   0.931   0.017   0.027\n",
            "*************** Epoch 50 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  RMSE  \n",
            "[300/876]  0.000   0.970   0.011   0.014\n",
            "[600/876]  0.002   0.810   0.026   0.040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = CNN_LSTM(seq_size=24*7)\n",
        "model7.to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model7.parameters(),\n",
        "                                lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "mse_metric = MeanSquaredError().to(device)\n",
        "mae_metric = MeanAbsoluteError().to(device)\n",
        "r2_metric = R2Score().to(device)\n",
        "train7_dataloader = DataLoader(train7_dataset,\n",
        "                              batch_size = 32, shuffle=True)"
      ],
      "metadata": {
        "id": "gpXsenKpgEs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning loop\n",
        "r2s = []\n",
        "maes = []\n",
        "rmses = []\n",
        "EPOCHS = 50\n",
        "\n",
        "n_total = len(train7_dataloader)\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  targets = []\n",
        "  print(f\"*************** Epoch {epoch} ***************\")\n",
        "  print(\" [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \")\n",
        "  for i, (inputs, target) in enumerate(train7_dataloader):\n",
        "    \n",
        "    inputs = inputs.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    predicted = model7(inputs)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(predicted, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "    if (i+1) % 300 == 0:\n",
        "      with torch.no_grad():\n",
        "        r2 = r2_metric(predicted, target)\n",
        "        mae = mae_metric(predicted, target)\n",
        "        mse = mse_metric(predicted, target)\n",
        "        print(f\"[{i+1}/{n_total}]  {loss.item():.3f}   {r2.item():.3f}   {mae.item():.3f}   {torch.sqrt(mse).item():.3f}\")\n",
        "  \n",
        "  r2s.append(r2.item())\n",
        "  maes.append(mae.item())\n",
        "  rmses.append(torch.sqrt(mse).item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsgDTqjegRo0",
        "outputId": "75b00685-b66e-42ad-c619-9cec56958663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************** Epoch 1 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.891   0.018   0.028\n",
            "[600/873]  0.001   0.822   0.030   0.038\n",
            "*************** Epoch 2 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.925   0.015   0.020\n",
            "[600/873]  0.001   0.954   0.017   0.025\n",
            "*************** Epoch 3 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.752   0.020   0.026\n",
            "[600/873]  0.000   0.946   0.017   0.021\n",
            "*************** Epoch 4 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.837   0.019   0.026\n",
            "[600/873]  0.000   0.935   0.018   0.022\n",
            "*************** Epoch 5 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.002   0.772   0.025   0.039\n",
            "[600/873]  0.001   0.961   0.020   0.023\n",
            "*************** Epoch 6 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.961   0.016   0.020\n",
            "[600/873]  0.001   0.914   0.018   0.024\n",
            "*************** Epoch 7 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.856   0.017   0.024\n",
            "[600/873]  0.000   0.945   0.014   0.017\n",
            "*************** Epoch 8 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.946   0.018   0.025\n",
            "[600/873]  0.001   0.928   0.022   0.025\n",
            "*************** Epoch 9 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.863   0.026   0.037\n",
            "[600/873]  0.001   0.911   0.020   0.025\n",
            "*************** Epoch 10 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.932   0.012   0.017\n",
            "[600/873]  0.000   0.902   0.017   0.022\n",
            "*************** Epoch 11 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.003   0.765   0.025   0.054\n",
            "[600/873]  0.000   0.883   0.016   0.020\n",
            "*************** Epoch 12 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.872   0.022   0.027\n",
            "[600/873]  0.001   0.894   0.021   0.027\n",
            "*************** Epoch 13 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.941   0.018   0.024\n",
            "[600/873]  0.001   0.905   0.021   0.025\n",
            "*************** Epoch 14 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.002   0.849   0.027   0.041\n",
            "[600/873]  0.000   0.913   0.016   0.022\n",
            "*************** Epoch 15 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.929   0.014   0.022\n",
            "[600/873]  0.000   0.949   0.017   0.021\n",
            "*************** Epoch 16 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.861   0.017   0.029\n",
            "[600/873]  0.000   0.939   0.015   0.018\n",
            "*************** Epoch 17 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.942   0.016   0.023\n",
            "[600/873]  0.000   0.964   0.015   0.018\n",
            "*************** Epoch 18 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.003   0.783   0.024   0.054\n",
            "[600/873]  0.001   0.943   0.019   0.026\n",
            "*************** Epoch 19 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.948   0.017   0.024\n",
            "[600/873]  0.002   0.891   0.025   0.044\n",
            "*************** Epoch 20 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.863   0.020   0.033\n",
            "[600/873]  0.001   0.864   0.022   0.027\n",
            "*************** Epoch 21 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.904   0.017   0.023\n",
            "[600/873]  0.000   0.940   0.011   0.014\n",
            "*************** Epoch 22 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.930   0.021   0.027\n",
            "[600/873]  0.001   0.934   0.021   0.028\n",
            "*************** Epoch 23 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.931   0.017   0.022\n",
            "[600/873]  0.001   0.948   0.016   0.028\n",
            "*************** Epoch 24 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.002   0.913   0.026   0.042\n",
            "[600/873]  0.001   0.925   0.023   0.028\n",
            "*************** Epoch 25 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.864   0.022   0.038\n",
            "[600/873]  0.000   0.942   0.013   0.015\n",
            "*************** Epoch 26 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.003   0.834   0.033   0.051\n",
            "[600/873]  0.000   0.917   0.014   0.020\n",
            "*************** Epoch 27 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.877   0.018   0.021\n",
            "[600/873]  0.001   0.891   0.021   0.026\n",
            "*************** Epoch 28 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.926   0.022   0.028\n",
            "[600/873]  0.002   0.857   0.025   0.042\n",
            "*************** Epoch 29 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.926   0.023   0.034\n",
            "[600/873]  0.001   0.902   0.019   0.025\n",
            "*************** Epoch 30 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.910   0.015   0.021\n",
            "[600/873]  0.001   0.952   0.020   0.027\n",
            "*************** Epoch 31 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.819   0.021   0.031\n",
            "[600/873]  0.000   0.947   0.014   0.017\n",
            "*************** Epoch 32 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.002   0.839   0.029   0.039\n",
            "[600/873]  0.002   0.860   0.024   0.040\n",
            "*************** Epoch 33 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.003   0.740   0.028   0.056\n",
            "[600/873]  0.004   0.774   0.032   0.062\n",
            "*************** Epoch 34 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.931   0.019   0.027\n",
            "[600/873]  0.000   0.962   0.013   0.017\n",
            "*************** Epoch 35 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.944   0.016   0.020\n",
            "[600/873]  0.000   0.919   0.015   0.019\n",
            "*************** Epoch 36 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.907   0.017   0.021\n",
            "[600/873]  0.000   0.922   0.015   0.021\n",
            "*************** Epoch 37 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.935   0.012   0.015\n",
            "[600/873]  0.001   0.841   0.017   0.024\n",
            "*************** Epoch 38 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.895   0.018   0.025\n",
            "[600/873]  0.001   0.846   0.025   0.035\n",
            "*************** Epoch 39 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.754   0.016   0.024\n",
            "[600/873]  0.001   0.930   0.019   0.027\n",
            "*************** Epoch 40 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.923   0.017   0.021\n",
            "[600/873]  0.000   0.951   0.017   0.021\n",
            "*************** Epoch 41 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.925   0.019   0.023\n",
            "[600/873]  0.002   0.644   0.029   0.050\n",
            "*************** Epoch 42 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.943   0.021   0.031\n",
            "[600/873]  0.001   0.864   0.022   0.029\n",
            "*************** Epoch 43 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.914   0.018   0.026\n",
            "[600/873]  0.000   0.930   0.017   0.021\n",
            "*************** Epoch 44 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.002   0.894   0.022   0.045\n",
            "[600/873]  0.000   0.927   0.013   0.018\n",
            "*************** Epoch 45 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.003   0.812   0.028   0.050\n",
            "[600/873]  0.001   0.944   0.015   0.025\n",
            "*************** Epoch 46 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.000   0.948   0.016   0.021\n",
            "[600/873]  0.001   0.878   0.022   0.036\n",
            "*************** Epoch 47 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.925   0.015   0.024\n",
            "[600/873]  0.002   0.819   0.025   0.040\n",
            "*************** Epoch 48 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.001   0.928   0.016   0.024\n",
            "[600/873]  0.002   0.903   0.026   0.044\n",
            "*************** Epoch 49 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.007   0.549   0.029   0.081\n",
            "[600/873]  0.000   0.970   0.014   0.017\n",
            "*************** Epoch 50 ***************\n",
            " [Epoch] |  Loss  |  R2  |  MAE  |  MSE  \n",
            "[300/873]  0.002   0.864   0.022   0.043\n",
            "[600/873]  0.000   0.931   0.017   0.022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Test"
      ],
      "metadata": {
        "id": "K0XlyFm4oPdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First test on `model1` on 24 hours dataset"
      ],
      "metadata": {
        "id": "wPDblgceqMMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  preds = model1(test1_dataset.input.to(device))\n",
        "  target = test1_dataset.target.to(device)\n",
        "  r2 = r2_metric(preds, target)\n",
        "  mae = mae_metric(preds, target)\n",
        "  mse = mse_metric(preds, target)\n",
        "  print(f\"R2: {r2.item():.3f}, MAE: {mae.item():.3f}, RMSE: {torch.sqrt(mse).item():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv2HAm2toVeD",
        "outputId": "9964d31b-0310-441e-f486-0ebf2cf6e5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2: 0.818, MAE: 0.028, RMSE: 0.040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test `model7` on 7 days test data"
      ],
      "metadata": {
        "id": "yW3-ktJ7qHj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  preds = model7(test7_dataset.input.to(device))\n",
        "  target = test7_dataset.target.to(device)\n",
        "  r2 = r2_metric(preds, target)\n",
        "  mae = mae_metric(preds, target)\n",
        "  mse = mse_metric(preds, target)\n",
        "  print(f\"R2: {r2.item():.3f}, MAE: {mae.item():.3f}, RMSE: {torch.sqrt(mse).item():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ5sRgw2op5s",
        "outputId": "65558c27-20d6-45bc-cb78-1f5c1709efd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2: 0.930, MAE: 0.016, RMSE: 0.025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2) Fake NEWS Detection"
      ],
      "metadata": {
        "id": "ajW1GktnLHC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Loading & Preprocessing The data"
      ],
      "metadata": {
        "id": "T8xZKmRysyBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if file is on colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cp drive/MyDrive/Datasets/NNDL_HW04/* ."
      ],
      "metadata": {
        "id": "MscKbxAK0Peo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./FA-KES-Dataset.csv\", encoding=\"unicode-escape\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "ohqpJZMbuN5W",
        "outputId": "b2f05218-421a-444d-8d21-f7c18b54e2fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        unit_id                                      article_title  \\\n",
              "0    1914947530  Syria attack symptoms consistent with nerve ag...   \n",
              "1    1914947532  Homs governor says U.S. attack caused deaths b...   \n",
              "2    1914947533    Death toll from Aleppo bomb attack at least 112   \n",
              "3    1914947534        Aleppo bomb blast kills six Syrian state TV   \n",
              "4    1914947535  29 Syria Rebels Dead in Fighting for Key Alepp...   \n",
              "..          ...                                                ...   \n",
              "799  1965511221    Turkish Bombardment Kills 20 Civilians in Syria   \n",
              "800  1965511222    Martyrs as Terrorists Shell Aleppos Salah Eddin   \n",
              "801  1965511224  Chemical Attack Kills Five Syrians in Aleppo SANA   \n",
              "802  1965511226  5 Killed as Russian Military Chopper Shot down...   \n",
              "803  1965511231  Syrian Army Kills 48 ISIL Terrorists in Deir E...   \n",
              "\n",
              "                                       article_content source       date  \\\n",
              "0    Wed 05 Apr 2017 Syria attack symptoms consiste...    nna   4/5/2017   \n",
              "1    Fri 07 Apr 2017 at 0914 Homs governor says U.S...    nna   4/7/2017   \n",
              "2    Sun 16 Apr 2017 Death toll from Aleppo bomb at...    nna  4/16/2017   \n",
              "3    Wed 19 Apr 2017 Aleppo bomb blast kills six Sy...    nna  4/19/2017   \n",
              "4    Sun 10 Jul 2016 29 Syria Rebels Dead in Fighti...    nna  7/10/2016   \n",
              "..                                                 ...    ...        ...   \n",
              "799  28-08-2016 Turkish Bombardment Kills 20 Civili...  manar  8/28/2016   \n",
              "800  17-08-2016 Martyrs as Terrorists Shell Aleppos...  manar   8/1/2016   \n",
              "801  03-08-2016 Chemical Attack Kills Five Syrians ...  manar   8/3/2016   \n",
              "802  01-08-2016 5 Killed as Russian Military Choppe...  manar   8/1/2016   \n",
              "803  April 6 2017 Syrian Army Kills 48 ISIL Terrori...  manar   4/4/2017   \n",
              "\n",
              "       location  labels  \n",
              "0         idlib       0  \n",
              "1          homs       0  \n",
              "2        aleppo       0  \n",
              "3        aleppo       0  \n",
              "4        aleppo       0  \n",
              "..          ...     ...  \n",
              "799      aleppo       1  \n",
              "800      aleppo       1  \n",
              "801      aleppo       0  \n",
              "802       idlib       1  \n",
              "803  deir ezzor       1  \n",
              "\n",
              "[804 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf163489-d099-47ad-9910-34da9b47ce81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_id</th>\n",
              "      <th>article_title</th>\n",
              "      <th>article_content</th>\n",
              "      <th>source</th>\n",
              "      <th>date</th>\n",
              "      <th>location</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1914947530</td>\n",
              "      <td>Syria attack symptoms consistent with nerve ag...</td>\n",
              "      <td>Wed 05 Apr 2017 Syria attack symptoms consiste...</td>\n",
              "      <td>nna</td>\n",
              "      <td>4/5/2017</td>\n",
              "      <td>idlib</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1914947532</td>\n",
              "      <td>Homs governor says U.S. attack caused deaths b...</td>\n",
              "      <td>Fri 07 Apr 2017 at 0914 Homs governor says U.S...</td>\n",
              "      <td>nna</td>\n",
              "      <td>4/7/2017</td>\n",
              "      <td>homs</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1914947533</td>\n",
              "      <td>Death toll from Aleppo bomb attack at least 112</td>\n",
              "      <td>Sun 16 Apr 2017 Death toll from Aleppo bomb at...</td>\n",
              "      <td>nna</td>\n",
              "      <td>4/16/2017</td>\n",
              "      <td>aleppo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1914947534</td>\n",
              "      <td>Aleppo bomb blast kills six Syrian state TV</td>\n",
              "      <td>Wed 19 Apr 2017 Aleppo bomb blast kills six Sy...</td>\n",
              "      <td>nna</td>\n",
              "      <td>4/19/2017</td>\n",
              "      <td>aleppo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1914947535</td>\n",
              "      <td>29 Syria Rebels Dead in Fighting for Key Alepp...</td>\n",
              "      <td>Sun 10 Jul 2016 29 Syria Rebels Dead in Fighti...</td>\n",
              "      <td>nna</td>\n",
              "      <td>7/10/2016</td>\n",
              "      <td>aleppo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>1965511221</td>\n",
              "      <td>Turkish Bombardment Kills 20 Civilians in Syria</td>\n",
              "      <td>28-08-2016 Turkish Bombardment Kills 20 Civili...</td>\n",
              "      <td>manar</td>\n",
              "      <td>8/28/2016</td>\n",
              "      <td>aleppo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>1965511222</td>\n",
              "      <td>Martyrs as Terrorists Shell Aleppos Salah Eddin</td>\n",
              "      <td>17-08-2016 Martyrs as Terrorists Shell Aleppos...</td>\n",
              "      <td>manar</td>\n",
              "      <td>8/1/2016</td>\n",
              "      <td>aleppo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>1965511224</td>\n",
              "      <td>Chemical Attack Kills Five Syrians in Aleppo SANA</td>\n",
              "      <td>03-08-2016 Chemical Attack Kills Five Syrians ...</td>\n",
              "      <td>manar</td>\n",
              "      <td>8/3/2016</td>\n",
              "      <td>aleppo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>1965511226</td>\n",
              "      <td>5 Killed as Russian Military Chopper Shot down...</td>\n",
              "      <td>01-08-2016 5 Killed as Russian Military Choppe...</td>\n",
              "      <td>manar</td>\n",
              "      <td>8/1/2016</td>\n",
              "      <td>idlib</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>1965511231</td>\n",
              "      <td>Syrian Army Kills 48 ISIL Terrorists in Deir E...</td>\n",
              "      <td>April 6 2017 Syrian Army Kills 48 ISIL Terrori...</td>\n",
              "      <td>manar</td>\n",
              "      <td>4/4/2017</td>\n",
              "      <td>deir ezzor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>804 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf163489-d099-47ad-9910-34da9b47ce81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf163489-d099-47ad-9910-34da9b47ce81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf163489-d099-47ad-9910-34da9b47ce81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles_list = df[\"article_content\"].to_list()\n",
        "labels_list = df[\"labels\"].to_list()"
      ],
      "metadata": {
        "id": "42e6cSQ4zGxq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "glove_vectors = GloVe(name=\"6B\", dim=100)"
      ],
      "metadata": {
        "id": "C31e9msJ4hTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "428babad-28aa-4d07-8064-9c7269609e6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:15<00:00, 25944.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now tokenize and embed the sentences  \n",
        "In here if sentence has more that 300 tokens we truncated it and if the sentence has less than 300 tokens we padded it with \" \" "
      ],
      "metadata": {
        "id": "_y9MrRBiOznQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "articles_emb = []\n",
        "for a in articles_list:\n",
        "  \n",
        "  tokens = tokenizer(a)\n",
        "  tokens_len = len(tokens)\n",
        "  if tokens_len < 300:\n",
        "    tokens.extend([\"\"]*(300-tokens_len))\n",
        "  elif tokens_len > 300:\n",
        "    tokens = tokens[:300]\n",
        "\n",
        "  embeddings = glove_vectors.get_vecs_by_tokens(tokens)\n",
        "  articles_emb.append(embeddings.unsqueeze(0))\n",
        "\n",
        "\n",
        "X = torch.cat(articles_emb)\n",
        "y = torch.tensor(labels_list)"
      ],
      "metadata": {
        "id": "Lp3GVUMd0x85"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data to train and test (80-20)"
      ],
      "metadata": {
        "id": "xh6V6YH2PWH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "WW-76dtEMchn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDataset(Dataset):\n",
        "  def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
        "    super().__init__()\n",
        "    self.input = X\n",
        "    self.target = y\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input[idx], self.target[idx]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.input.shape[0]"
      ],
      "metadata": {
        "id": "li5bEysMNbZ2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NewsDataset(X_train, y_train)\n",
        "test_dataset = NewsDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "JT0nW3RENusH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Building the models"
      ],
      "metadata": {
        "id": "rhoEDjw6MowO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First build the `hybrid(CNN-RNN)`"
      ],
      "metadata": {
        "id": "MpkIp0mkrR2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Hybrid(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv1d(300, 128, 5)     # 300 * 100 -> 128 * 96\n",
        "    self.maxpool = nn.MaxPool1d(2)          # 128 * 94 -> 128 * 48\n",
        "    self.lstm = nn.LSTM(input_size=48, hidden_size=32, batch_first=True)\n",
        "    self.fc = nn.Linear(32*128, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.lstm(x)[0]\n",
        "    x = x.reshape((-1, 32*128))\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "5n0OTtF_N6Fc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now build a simple `RNN` model"
      ],
      "metadata": {
        "id": "klDi8PDcYp9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.lstm1 = nn.LSTM(input_size=100, hidden_size=64, batch_first=True)\n",
        "    self.lstm2 = nn.LSTM(input_size=64, hidden_size=32, batch_first=True)\n",
        "    self.lstm3 = nn.LSTM(input_size=32, hidden_size=8, batch_first=True)\n",
        "    self.fc = nn.Linear(300*8, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.lstm1(x)[0]\n",
        "    x = self.lstm2(x)[0]\n",
        "    x = self.lstm3(x)[0]\n",
        "    x = x.reshape((-1, 300*8))\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "c5z3wdMzXg_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Training"
      ],
      "metadata": {
        "id": "FSs--RTiN7V-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.) Hybrid CNN-RNN model"
      ],
      "metadata": {
        "id": "nOrxl3m2Ytjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_hyb = Hybrid()\n",
        "model_hyb.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_hyb.parameters(),\n",
        "                                lr=0.01)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size = 64, shuffle=True)"
      ],
      "metadata": {
        "id": "cH9oUiHCN6Ng"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning loop\n",
        "f1_list = []\n",
        "prec_list = []\n",
        "acc_list = []\n",
        "rec_list = []\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "n_total = len(train_dataloader)\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  targets = []\n",
        "  print(f\"*************** Epoch {epoch} ***************\")\n",
        "  print(\" [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \")\n",
        "  for i, (inputs, target) in enumerate(train_dataloader):\n",
        "    \n",
        "    inputs = inputs.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    predicted = model_hyb(inputs)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(predicted, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "    if (i+1) % 3 == 0:\n",
        "      with torch.no_grad():\n",
        "        ac = multiclass_accuracy(predicted, target, num_classes=2).item()\n",
        "        pr = multiclass_precision(predicted, target, num_classes=2).item()\n",
        "        f1 = multiclass_f1_score(predicted, target, num_classes=2).item()\n",
        "        re = multiclass_recall(predicted, target, num_classes=2).item()\n",
        "        f1_list.append(f1)\n",
        "        prec_list.append(pr)\n",
        "        acc_list.append(ac)\n",
        "        rec_list.append(re)\n",
        "        print(f\" [{i+1}/{n_total}]  |   {loss.item():.3f}  |  {ac:.3f}  |  {pr:.3f}  |  {f1:.3f}  |  {re:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eThjf9f6yW23",
        "outputId": "3a452730-303c-4a4c-a122-1f38fbe914e0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************** Epoch 1 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   2.345  |  0.500  |  0.297  |  0.373  |  0.500\n",
            " [6/11]  |   0.965  |  0.500  |  0.250  |  0.333  |  0.500\n",
            " [9/11]  |   0.882  |  0.500  |  0.281  |  0.360  |  0.500\n",
            "*************** Epoch 2 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.729  |  0.500  |  0.273  |  0.354  |  0.500\n",
            " [6/11]  |   0.803  |  0.500  |  0.234  |  0.319  |  0.500\n",
            " [9/11]  |   0.686  |  0.488  |  0.310  |  0.379  |  0.488\n",
            "*************** Epoch 3 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.778  |  0.500  |  0.250  |  0.333  |  0.500\n",
            " [6/11]  |   0.686  |  0.500  |  0.289  |  0.366  |  0.500\n",
            " [9/11]  |   0.696  |  0.504  |  0.509  |  0.428  |  0.504\n",
            "*************** Epoch 4 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.703  |  0.571  |  0.631  |  0.479  |  0.571\n",
            " [6/11]  |   0.716  |  0.515  |  0.738  |  0.351  |  0.515\n",
            " [9/11]  |   0.750  |  0.478  |  0.175  |  0.256  |  0.478\n",
            "*************** Epoch 5 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.712  |  0.503  |  0.524  |  0.383  |  0.503\n",
            " [6/11]  |   0.695  |  0.500  |  0.250  |  0.333  |  0.500\n",
            " [9/11]  |   0.685  |  0.500  |  0.266  |  0.347  |  0.500\n",
            "*************** Epoch 6 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.688  |  0.498  |  0.492  |  0.373  |  0.498\n",
            " [6/11]  |   0.673  |  0.447  |  0.283  |  0.347  |  0.447\n",
            " [9/11]  |   0.669  |  0.554  |  0.795  |  0.468  |  0.554\n",
            "*************** Epoch 7 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.716  |  0.500  |  0.203  |  0.289  |  0.500\n",
            " [6/11]  |   0.689  |  0.500  |  0.234  |  0.319  |  0.500\n",
            " [9/11]  |   0.664  |  0.569  |  0.792  |  0.490  |  0.569\n",
            "*************** Epoch 8 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.651  |  0.537  |  0.798  |  0.443  |  0.537\n",
            " [6/11]  |   0.640  |  0.516  |  0.762  |  0.375  |  0.516\n",
            " [9/11]  |   0.665  |  0.514  |  0.722  |  0.335  |  0.514\n",
            "*************** Epoch 9 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.641  |  0.735  |  0.812  |  0.705  |  0.735\n",
            " [6/11]  |   0.584  |  0.883  |  0.915  |  0.887  |  0.883\n",
            " [9/11]  |   0.597  |  0.827  |  0.828  |  0.828  |  0.827\n",
            "*************** Epoch 10 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.507  |  0.870  |  0.920  |  0.882  |  0.870\n",
            " [6/11]  |   0.497  |  0.922  |  0.926  |  0.922  |  0.922\n",
            " [9/11]  |   0.455  |  0.938  |  0.939  |  0.937  |  0.938\n",
            "*************** Epoch 11 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.405  |  0.908  |  0.906  |  0.906  |  0.908\n",
            " [6/11]  |   0.289  |  0.917  |  0.955  |  0.931  |  0.917\n",
            " [9/11]  |   0.354  |  0.925  |  0.900  |  0.904  |  0.925\n",
            "*************** Epoch 12 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.195  |  0.985  |  0.984  |  0.984  |  0.985\n",
            " [6/11]  |   0.224  |  0.986  |  0.982  |  0.984  |  0.986\n",
            " [9/11]  |   0.193  |  0.962  |  0.975  |  0.967  |  0.962\n",
            "*************** Epoch 13 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.115  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.103  |  0.986  |  0.983  |  0.984  |  0.986\n",
            " [9/11]  |   0.154  |  0.935  |  0.966  |  0.947  |  0.935\n",
            "*************** Epoch 14 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.154  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [6/11]  |   0.081  |  0.985  |  0.984  |  0.984  |  0.985\n",
            " [9/11]  |   0.148  |  0.969  |  0.969  |  0.969  |  0.969\n",
            "*************** Epoch 15 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.090  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.051  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.203  |  0.953  |  0.957  |  0.953  |  0.953\n",
            "*************** Epoch 16 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.038  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.145  |  0.977  |  0.988  |  0.982  |  0.977\n",
            " [9/11]  |   0.072  |  0.986  |  0.982  |  0.984  |  0.986\n",
            "*************** Epoch 17 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.031  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [6/11]  |   0.089  |  0.971  |  0.968  |  0.969  |  0.971\n",
            " [9/11]  |   0.032  |  0.985  |  0.984  |  0.984  |  0.985\n",
            "*************** Epoch 18 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.031  |  0.981  |  0.987  |  0.984  |  0.981\n",
            " [6/11]  |   0.016  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.036  |  0.983  |  0.986  |  0.984  |  0.983\n",
            "*************** Epoch 19 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.047  |  0.969  |  0.969  |  0.969  |  0.969\n",
            " [6/11]  |   0.012  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.126  |  0.984  |  0.985  |  0.984  |  0.984\n",
            "*************** Epoch 20 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.008  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.031  |  0.985  |  0.984  |  0.984  |  0.985\n",
            " [9/11]  |   0.034  |  0.984  |  0.985  |  0.984  |  0.984\n",
            "*************** Epoch 21 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.040  |  0.971  |  0.969  |  0.969  |  0.971\n",
            " [6/11]  |   0.035  |  0.972  |  0.967  |  0.968  |  0.972\n",
            " [9/11]  |   0.005  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 22 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.006  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.006  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.017  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 23 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.010  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.005  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.032  |  0.969  |  0.969  |  0.969  |  0.969\n",
            "*************** Epoch 24 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.029  |  0.985  |  0.984  |  0.984  |  0.985\n",
            " [6/11]  |   0.005  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.055  |  0.954  |  0.949  |  0.952  |  0.954\n",
            "*************** Epoch 25 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.004  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.004  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.072  |  0.953  |  0.954  |  0.953  |  0.953\n",
            "*************** Epoch 26 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.025  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [6/11]  |   0.003  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.107  |  0.970  |  0.970  |  0.969  |  0.970\n",
            "*************** Epoch 27 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.111  |  0.969  |  0.969  |  0.969  |  0.969\n",
            " [6/11]  |   0.027  |  0.968  |  0.968  |  0.968  |  0.968\n",
            " [9/11]  |   0.064  |  0.969  |  0.969  |  0.969  |  0.969\n",
            "*************** Epoch 28 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.010  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.080  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.028  |  0.968  |  0.971  |  0.969  |  0.968\n",
            "*************** Epoch 29 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.036  |  0.968  |  0.968  |  0.968  |  0.968\n",
            " [6/11]  |   0.004  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.013  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 30 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.010  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.036  |  0.986  |  0.983  |  0.984  |  0.986\n",
            " [9/11]  |   0.017  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 31 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.006  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.037  |  0.985  |  0.984  |  0.984  |  0.985\n",
            " [9/11]  |   0.107  |  0.964  |  0.974  |  0.968  |  0.964\n",
            "*************** Epoch 32 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.053  |  0.986  |  0.983  |  0.984  |  0.986\n",
            " [6/11]  |   0.006  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.032  |  0.984  |  0.985  |  0.984  |  0.984\n",
            "*************** Epoch 33 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.028  |  0.981  |  0.987  |  0.984  |  0.981\n",
            " [6/11]  |   0.017  |  0.987  |  0.981  |  0.984  |  0.987\n",
            " [9/11]  |   0.021  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 34 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.026  |  0.983  |  0.986  |  0.984  |  0.983\n",
            " [6/11]  |   0.072  |  0.969  |  0.969  |  0.969  |  0.969\n",
            " [9/11]  |   0.003  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 35 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.015  |  0.985  |  0.984  |  0.984  |  0.985\n",
            " [6/11]  |   0.011  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.012  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 36 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.012  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.002  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.027  |  0.987  |  0.981  |  0.984  |  0.987\n",
            "*************** Epoch 37 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.062  |  0.952  |  0.958  |  0.953  |  0.952\n",
            " [6/11]  |   0.030  |  0.980  |  0.988  |  0.983  |  0.980\n",
            " [9/11]  |   0.002  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 38 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.014  |  0.980  |  0.988  |  0.983  |  0.980\n",
            " [6/11]  |   0.021  |  0.987  |  0.981  |  0.984  |  0.987\n",
            " [9/11]  |   0.042  |  0.973  |  0.966  |  0.968  |  0.973\n",
            "*************** Epoch 39 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.006  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.006  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.037  |  0.964  |  0.974  |  0.968  |  0.964\n",
            "*************** Epoch 40 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.013  |  0.986  |  0.983  |  0.984  |  0.986\n",
            " [6/11]  |   0.013  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.029  |  0.985  |  0.984  |  0.984  |  0.985\n",
            "*************** Epoch 41 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.043  |  0.966  |  0.973  |  0.968  |  0.966\n",
            " [6/11]  |   0.051  |  0.968  |  0.968  |  0.968  |  0.968\n",
            " [9/11]  |   0.021  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 42 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.001  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.049  |  0.954  |  0.953  |  0.953  |  0.954\n",
            " [9/11]  |   0.023  |  0.986  |  0.983  |  0.984  |  0.986\n",
            "*************** Epoch 43 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.034  |  0.986  |  0.983  |  0.984  |  0.986\n",
            " [6/11]  |   0.029  |  0.969  |  0.969  |  0.969  |  0.969\n",
            " [9/11]  |   0.022  |  0.986  |  0.983  |  0.984  |  0.986\n",
            "*************** Epoch 44 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.012  |  0.983  |  0.986  |  0.984  |  0.983\n",
            " [6/11]  |   0.024  |  0.981  |  0.987  |  0.984  |  0.981\n",
            " [9/11]  |   0.001  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 45 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.053  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [6/11]  |   0.035  |  0.970  |  0.970  |  0.969  |  0.970\n",
            " [9/11]  |   0.023  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 46 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.014  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [6/11]  |   0.016  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.011  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 47 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.001  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.027  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.031  |  0.967  |  0.967  |  0.967  |  0.967\n",
            "*************** Epoch 48 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.011  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.023  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.047  |  0.968  |  0.968  |  0.968  |  0.968\n",
            "*************** Epoch 49 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.023  |  0.987  |  0.981  |  0.984  |  0.987\n",
            " [6/11]  |   0.034  |  0.966  |  0.966  |  0.966  |  0.966\n",
            " [9/11]  |   0.021  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 50 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.013  |  0.982  |  0.986  |  0.984  |  0.982\n",
            " [6/11]  |   0.016  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.036  |  0.971  |  0.968  |  0.969  |  0.971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(f1_list)\n",
        "plt.plot(prec_list)\n",
        "plt.plot(acc_list)\n",
        "plt.plot(rec_list)\n",
        "plt.legend((\"F1\", \"Precision\", \"Accuracy\", \"Recall\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "etXA5DSqZC7a",
        "outputId": "d195d90b-1bc2-4cf2-c498-78ea88413b8c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. RNN model"
      ],
      "metadata": {
        "id": "YoJNXwEnYynF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn = Hybrid()\n",
        "model_rnn.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_rnn.parameters(),\n",
        "                                lr=0.01)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size = 64, shuffle=True)"
      ],
      "metadata": {
        "id": "J8mrdMHWY71p"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning loop\n",
        "f1_list = []\n",
        "prec_list = []\n",
        "acc_list = []\n",
        "rec_list = []\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "n_total = len(train_dataloader)\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  targets = []\n",
        "  print(f\"*************** Epoch {epoch} ***************\")\n",
        "  print(\" [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \")\n",
        "  for i, (inputs, target) in enumerate(train_dataloader):\n",
        "    \n",
        "    inputs = inputs.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    predicted = model_rnn(inputs)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(predicted, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "    if (i+1) % 3 == 0:\n",
        "      with torch.no_grad():\n",
        "        ac = multiclass_accuracy(predicted, target, num_classes=2).item()\n",
        "        pr = multiclass_precision(predicted, target, num_classes=2).item()\n",
        "        f1 = multiclass_f1_score(predicted, target, num_classes=2).item()\n",
        "        re = multiclass_recall(predicted, target, num_classes=2).item()\n",
        "        f1_list.append(f1)\n",
        "        prec_list.append(pr)\n",
        "        acc_list.append(ac)\n",
        "        rec_list.append(re)\n",
        "        print(f\" [{i+1}/{n_total}]  |   {loss.item():.3f}  |  {ac:.3f}  |  {pr:.3f}  |  {f1:.3f}  |  {re:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aCsRbFBZGLF",
        "outputId": "05665707-07c8-41c7-d97c-35354d2f9eb7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************** Epoch 1 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   4.745  |  0.500  |  0.188  |  0.273  |  0.500\n",
            " [6/11]  |   0.727  |  0.456  |  0.419  |  0.401  |  0.456\n",
            " [9/11]  |   0.705  |  0.500  |  0.500  |  0.433  |  0.500\n",
            "*************** Epoch 2 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.688  |  0.509  |  0.518  |  0.478  |  0.509\n",
            " [6/11]  |   0.698  |  0.536  |  0.536  |  0.531  |  0.536\n",
            " [9/11]  |   0.694  |  0.484  |  0.238  |  0.319  |  0.484\n",
            "*************** Epoch 3 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.687  |  0.500  |  0.242  |  0.326  |  0.500\n",
            " [6/11]  |   0.694  |  0.500  |  0.219  |  0.304  |  0.500\n",
            " [9/11]  |   0.696  |  0.500  |  0.203  |  0.289  |  0.500\n",
            "*************** Epoch 4 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.694  |  0.500  |  0.234  |  0.319  |  0.500\n",
            " [6/11]  |   0.692  |  0.500  |  0.289  |  0.366  |  0.500\n",
            " [9/11]  |   0.693  |  0.500  |  0.281  |  0.360  |  0.500\n",
            "*************** Epoch 5 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.689  |  0.500  |  0.242  |  0.326  |  0.500\n",
            " [6/11]  |   0.692  |  0.500  |  0.250  |  0.333  |  0.500\n",
            " [9/11]  |   0.698  |  0.500  |  0.203  |  0.289  |  0.500\n",
            "*************** Epoch 6 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.701  |  0.500  |  0.234  |  0.319  |  0.500\n",
            " [6/11]  |   0.689  |  0.500  |  0.266  |  0.347  |  0.500\n",
            " [9/11]  |   0.695  |  0.500  |  0.250  |  0.333  |  0.500\n",
            "*************** Epoch 7 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.683  |  0.534  |  0.782  |  0.425  |  0.534\n",
            " [6/11]  |   0.684  |  0.567  |  0.783  |  0.479  |  0.567\n",
            " [9/11]  |   0.689  |  0.531  |  0.531  |  0.531  |  0.531\n",
            "*************** Epoch 8 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.690  |  0.530  |  0.531  |  0.515  |  0.530\n",
            " [6/11]  |   0.688  |  0.611  |  0.613  |  0.611  |  0.611\n",
            " [9/11]  |   0.685  |  0.521  |  0.530  |  0.492  |  0.521\n",
            "*************** Epoch 9 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.674  |  0.537  |  0.798  |  0.443  |  0.537\n",
            " [6/11]  |   0.669  |  0.517  |  0.778  |  0.390  |  0.517\n",
            " [9/11]  |   0.668  |  0.821  |  0.847  |  0.823  |  0.821\n",
            "*************** Epoch 10 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.656  |  0.652  |  0.787  |  0.597  |  0.652\n",
            " [6/11]  |   0.654  |  0.660  |  0.746  |  0.613  |  0.660\n",
            " [9/11]  |   0.629  |  0.825  |  0.831  |  0.826  |  0.825\n",
            "*************** Epoch 11 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.587  |  0.734  |  0.827  |  0.714  |  0.734\n",
            " [6/11]  |   0.596  |  0.858  |  0.863  |  0.859  |  0.858\n",
            " [9/11]  |   0.561  |  0.814  |  0.812  |  0.812  |  0.814\n",
            "*************** Epoch 12 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.498  |  0.914  |  0.914  |  0.906  |  0.914\n",
            " [6/11]  |   0.428  |  0.929  |  0.950  |  0.935  |  0.929\n",
            " [9/11]  |   0.379  |  0.983  |  0.986  |  0.984  |  0.983\n",
            "*************** Epoch 13 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.367  |  0.941  |  0.933  |  0.936  |  0.941\n",
            " [6/11]  |   0.285  |  0.952  |  0.958  |  0.953  |  0.952\n",
            " [9/11]  |   0.292  |  0.954  |  0.948  |  0.951  |  0.954\n",
            "*************** Epoch 14 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.185  |  0.953  |  0.954  |  0.953  |  0.953\n",
            " [6/11]  |   0.229  |  0.948  |  0.961  |  0.952  |  0.948\n",
            " [9/11]  |   0.263  |  0.921  |  0.923  |  0.921  |  0.921\n",
            "*************** Epoch 15 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.057  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.113  |  0.966  |  0.973  |  0.968  |  0.966\n",
            " [9/11]  |   0.130  |  0.969  |  0.969  |  0.969  |  0.969\n",
            "*************** Epoch 16 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.137  |  0.953  |  0.957  |  0.953  |  0.953\n",
            " [6/11]  |   0.082  |  0.963  |  0.974  |  0.968  |  0.963\n",
            " [9/11]  |   0.077  |  0.986  |  0.983  |  0.984  |  0.986\n",
            "*************** Epoch 17 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.077  |  0.968  |  0.971  |  0.969  |  0.968\n",
            " [6/11]  |   0.127  |  0.951  |  0.954  |  0.953  |  0.951\n",
            " [9/11]  |   0.055  |  0.986  |  0.983  |  0.984  |  0.986\n",
            "*************** Epoch 18 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.044  |  0.986  |  0.983  |  0.984  |  0.986\n",
            " [6/11]  |   0.040  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.047  |  0.986  |  0.983  |  0.984  |  0.986\n",
            "*************** Epoch 19 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.013  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.040  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.019  |  0.985  |  0.984  |  0.984  |  0.985\n",
            "*************** Epoch 20 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.031  |  0.983  |  0.986  |  0.984  |  0.983\n",
            " [6/11]  |   0.024  |  0.982  |  0.986  |  0.984  |  0.982\n",
            " [9/11]  |   0.059  |  0.974  |  0.964  |  0.968  |  0.974\n",
            "*************** Epoch 21 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.003  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.019  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.024  |  0.981  |  0.987  |  0.984  |  0.981\n",
            "*************** Epoch 22 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.019  |  0.983  |  0.986  |  0.984  |  0.983\n",
            " [6/11]  |   0.030  |  0.981  |  0.987  |  0.984  |  0.981\n",
            " [9/11]  |   0.003  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 23 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.040  |  0.968  |  0.971  |  0.969  |  0.968\n",
            " [6/11]  |   0.030  |  0.985  |  0.984  |  0.984  |  0.985\n",
            " [9/11]  |   0.013  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 24 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.023  |  0.983  |  0.986  |  0.984  |  0.983\n",
            " [6/11]  |   0.027  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.002  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 25 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.022  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [6/11]  |   0.025  |  0.986  |  0.983  |  0.984  |  0.986\n",
            " [9/11]  |   0.037  |  0.981  |  0.987  |  0.984  |  0.981\n",
            "*************** Epoch 26 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.037  |  0.968  |  0.968  |  0.968  |  0.968\n",
            " [6/11]  |   0.015  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.015  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 27 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.039  |  0.970  |  0.970  |  0.969  |  0.970\n",
            " [6/11]  |   0.024  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.039  |  0.970  |  0.970  |  0.969  |  0.970\n",
            "*************** Epoch 28 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.030  |  0.980  |  0.988  |  0.983  |  0.980\n",
            " [6/11]  |   0.010  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.027  |  0.986  |  0.983  |  0.984  |  0.986\n",
            "*************** Epoch 29 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.032  |  0.971  |  0.969  |  0.969  |  0.971\n",
            " [6/11]  |   0.013  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.025  |  0.986  |  0.982  |  0.984  |  0.986\n",
            "*************** Epoch 30 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.020  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.042  |  0.969  |  0.969  |  0.969  |  0.969\n",
            " [9/11]  |   0.021  |  0.985  |  0.984  |  0.984  |  0.985\n",
            "*************** Epoch 31 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.001  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.066  |  0.954  |  0.949  |  0.952  |  0.954\n",
            " [9/11]  |   0.014  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 32 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.053  |  0.967  |  0.967  |  0.967  |  0.967\n",
            " [6/11]  |   0.007  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.028  |  0.986  |  0.983  |  0.984  |  0.986\n",
            "*************** Epoch 33 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.018  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.038  |  0.971  |  0.968  |  0.969  |  0.971\n",
            " [9/11]  |   0.044  |  0.983  |  0.986  |  0.984  |  0.983\n",
            "*************** Epoch 34 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.039  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [6/11]  |   0.018  |  0.986  |  0.982  |  0.984  |  0.986\n",
            " [9/11]  |   0.017  |  0.986  |  0.983  |  0.984  |  0.986\n",
            "*************** Epoch 35 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.032  |  0.985  |  0.984  |  0.984  |  0.985\n",
            " [6/11]  |   0.031  |  0.985  |  0.984  |  0.984  |  0.985\n",
            " [9/11]  |   0.001  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 36 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.033  |  0.969  |  0.969  |  0.969  |  0.969\n",
            " [6/11]  |   0.105  |  0.923  |  0.921  |  0.922  |  0.923\n",
            " [9/11]  |   0.001  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 37 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.002  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.019  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.019  |  0.982  |  0.986  |  0.984  |  0.982\n",
            "*************** Epoch 38 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.027  |  0.970  |  0.970  |  0.969  |  0.970\n",
            " [6/11]  |   0.035  |  0.971  |  0.968  |  0.969  |  0.971\n",
            " [9/11]  |   0.052  |  0.967  |  0.972  |  0.968  |  0.967\n",
            "*************** Epoch 39 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.014  |  0.986  |  0.982  |  0.984  |  0.986\n",
            " [6/11]  |   0.067  |  0.969  |  0.969  |  0.969  |  0.969\n",
            " [9/11]  |   0.018  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 40 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.012  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [6/11]  |   0.033  |  0.987  |  0.981  |  0.984  |  0.987\n",
            " [9/11]  |   0.049  |  0.961  |  0.948  |  0.952  |  0.961\n",
            "*************** Epoch 41 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.012  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [6/11]  |   0.015  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.001  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 42 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.014  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.015  |  0.981  |  0.987  |  0.984  |  0.981\n",
            " [9/11]  |   0.025  |  0.986  |  0.983  |  0.984  |  0.986\n",
            "*************** Epoch 43 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.007  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.002  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.047  |  0.971  |  0.969  |  0.969  |  0.971\n",
            "*************** Epoch 44 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.062  |  0.986  |  0.983  |  0.984  |  0.986\n",
            " [6/11]  |   0.008  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [9/11]  |   0.010  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 45 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.001  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.049  |  0.968  |  0.968  |  0.968  |  0.968\n",
            " [9/11]  |   0.054  |  0.983  |  0.986  |  0.984  |  0.983\n",
            "*************** Epoch 46 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.032  |  0.983  |  0.986  |  0.984  |  0.983\n",
            " [6/11]  |   0.055  |  0.953  |  0.954  |  0.953  |  0.953\n",
            " [9/11]  |   0.023  |  0.985  |  0.984  |  0.984  |  0.985\n",
            "*************** Epoch 47 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.001  |  1.000  |  1.000  |  1.000  |  1.000\n",
            " [6/11]  |   0.037  |  0.969  |  0.969  |  0.969  |  0.969\n",
            " [9/11]  |   0.034  |  0.988  |  0.980  |  0.983  |  0.988\n",
            "*************** Epoch 48 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.020  |  0.987  |  0.981  |  0.984  |  0.987\n",
            " [6/11]  |   0.047  |  0.984  |  0.985  |  0.984  |  0.984\n",
            " [9/11]  |   0.001  |  1.000  |  1.000  |  1.000  |  1.000\n",
            "*************** Epoch 49 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.021  |  0.983  |  0.986  |  0.984  |  0.983\n",
            " [6/11]  |   0.018  |  0.985  |  0.984  |  0.984  |  0.985\n",
            " [9/11]  |   0.019  |  0.988  |  0.980  |  0.983  |  0.988\n",
            "*************** Epoch 50 ***************\n",
            " [Epoch] |   Loss   |   Acc   |   Pre   |   F1    |  Recall \n",
            " [3/11]  |   0.012  |  0.981  |  0.987  |  0.984  |  0.981\n",
            " [6/11]  |   0.027  |  0.968  |  0.968  |  0.968  |  0.968\n",
            " [9/11]  |   0.039  |  0.968  |  0.968  |  0.968  |  0.968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(f1_list)\n",
        "plt.plot(prec_list)\n",
        "plt.plot(acc_list)\n",
        "plt.plot(rec_list)\n",
        "plt.legend((\"F1\", \"Precision\", \"Accuracy\", \"Recall\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "fs43BFJQbP1Q",
        "outputId": "2aae4a27-275c-4585-ba13-9ac07aba0f54"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxU1fn48c+ZfSb7HkgICWEJq4AIKFJwZRFBrbs/t1qXurWutYvUpVq1rbW2frV2sdpaKVIXtChWwZ19FUgIIUBIyL4vs92Z8/vjTvaETMgESDzv1ysvMveeuffMJDzz5LnnniOklCiKoigDn+FEd0BRFEUJDRXQFUVRBgkV0BVFUQYJFdAVRVEGCRXQFUVRBgnTiTpxfHy8TE9PP1GnVxRFGZC2bNlSIaVM6GrfCQvo6enpbN68+USdXlEUZUASQhzqbp8quSiKogwSKqAriqIMEiqgK4qiDBIqoCuKogwSKqAriqIMEj0GdCHE34QQZUKIXd3sF0KI54UQeUKInUKIqaHvpqIoitKTYDL0vwPzj7J/ATAq8HUL8GLfu6UoiqL0Vo8BXUr5OVB1lCZLgNekbj0QLYQYEqoOKsfHF2+9wPsvPBCy49VWFbPiJxdTXV4EgKupgeU/u4Lig9lBH+OtJ29i2Y2zWHbjLNYse67bdmtef4b3/3hfp+2bP17GW098r9P2fTu/ZPlDl+LTtKD64WysY9n9F1JWtL/Htisev4GN/1veaft7z9/LJ6//uuXxh39Zyuq//KJTuy/ffZl3f3tHy+PtX7zLW0/e1PI4Z9unLP9Ja98L8nby7weWoHk9Qb2Wrix/+Ep2rf+g0/a3n7ql5f3/7N+/O+bj7/zqPd78xdVBt6+pLGbZXeez7MZZvHHrWZR2eN99msa/H1is9+2m2V32/d1nbm7pe/PXJ68/E3QfNnz4Wrv3vTtF+btY/uBFuJ2NQR+7X0kpe/wC0oFd3ex7HzizzeNPgGndtL0F2AxsTktLk8rJ450F4+WGyVnS63KG5Hhv3DBL7hmTJd+47nT98Y8ukHvGZMnll08J6vllxQVy+7gsuWeM/rXmjCzpqi3v1K6+olB+Pj1Lrp+SJb1ud8t2r8ctP5qdJXeNyZJfLP9tu+e8vWiC3DMmS/7niRuD6suyexfqr+Wu84/absObv5G7xmTJj74zVno9rX1xO5vkhslZct3ULFl6JF/u271Bbp6YJT+bkdXu+U0NtXLt6Vly88Sslucvv3yq3DUmSx7K2aL35doZgb7fJKWUcsXFk+WeMVnyvy8+FNRr6Wjlcz8K/Fymdn49k1vf/8+nZ8n66s7vfzDevFTv4wcv/TSo9m/cdKbcM0b/2e0ZkyWXf29Gu/3Lf3FtS7/2jMmS/75yWrv9n7/9J7krK6vlGM3H+XDu2KDO73Y2yY/PzJI7x2bJ4kO5R227/PIpcs+YLPnmj5cEdexQADbLbmL1cb0oKqV8WUo5TUo5LSGhyztXlRMkrMFHhBPWv/N8n4+14+sPGL+hEqcFxm+q5rP/vMjINfvRDJD1jZOtH73W4zG++PuTWHyw/wfns/OqM0iuhE9/0znLW/vUNcTXQmQTrHv3/1q2v/349aSW6d9X/vMv4NMz2o9ffZwx+zT8AqJXrcPdVHfUflSXHCLts3wAwvYVdd/QWU3xij9jAFJLJW893vqXwedvPkeEE6IaYe3917LjZ7fj8EBCDWz77O2WdisfuZakKnB4aMk6I8ucGIBNK/4IQMwhvb+J73zFR68+xbg9LgDqvv70qK+jK163C8eKD/XjFTS1f93lR4hwwo7ZCey95Xzia2HVI8Fn2c18mkbyIb2PYtnb+DTvUdvv3/klozdWsHekifE52eQNN5O6o5aKbe8BUFl2mGHvbaIwGUZs20RehoHkAw0tz/f7/dS98DxNVnC8/Srjc7IZn5PNjpnRDC2VlBTs67HP7z5+PUPLweSHdct+2227LatfJesbJwDxn++loexAj8fub6EI6EXAsDaPUwPblBPB6wK/v9dPiwj8nyj58v1jPnXpoWwKcjZR8OhDeMxQdfMcPCaIXvo8Vi/kXz8Lv4BDLz4DbVfKaiiDshw4sg00NwByw0bqHHDmFXdz4f3PUusA36ZDeDf8BaoPQm0Rzg2vYttUQm2YfpjiT98FoK6qlKEfbKcoEXbMTGJkrmT9K/fh07x4//EGdQ7YsXgiQyrg/ceuAfRAgKcJCre0e03/e/RaohvgcJJgWKGPhpryLl/7kWV3k5It2DU2isNDIO2/W6ipLAWg4tMP8AvIzYJJWyoZl93IvtH683Lf/zsAVaWHSVubS61D357/1So0zUtihf4++b7ZSdGBPaSUSQ6kQVwdJD3zKtXhUDAEkvNqWjvT5ufvcTaRs+FD8nZ8RsWR/Xg9rpZ9bz+mB66DKYLEar000mz/zs8BMMQncOEPn+XgUAPDvjxMef5WKM8FZ3W3vwdNDTWUFeYCsG3tm8TVQUGyIK1YsvLp71N6KJvsdf/t8rlbn/ohVi8k3q6X/0xX/T+iG2DrXx6Exko+fvB6IhpBXjIXqz2cxlFDSaiB7Z+9BcB7f/wJIw77ODArkeFjp7ccN/zUMzD5Yf3yQOlIc0PdEXDWtHu/qitKSPnoG4oSwW0C7zZ9epKSQ3tY/fRdrHnpYTb/9xU8rkYKXvo1fgHbFk0kqQrWPHM9SInf7ydn42rWvPhzasoL4cj29r/v/SgUAX0lcF1gtMtMoFZKWRyC4yq95fex55FTyHvr0V49rb6mnMhAgmY5VH7UX753fnsfX502jrKi/Hbb1yz7A1XzLqHxousYechDwXQL5975Igemh2Hxwb5JRpY8+Gf2TI1jdI6P9y8Yx0dzx7FyyVg+uec0Nv3ybHKenU/5Oz/D2VRHxv4mijMgOjkTR1gUB+acQsYBA7n/fpjPfzqbTx88nU1/f5jUEkHBkrMojwb7AT2AfvDz/0dsPTR+93xmL30RzQg1yz9k1eUTSC+U7P/OCC5/4nWOxAtSP8rjs9PHsXPSeFZeM4XiF+bh3r0KgJLczaSvLydvuJH6BWdi9cLnrz9NXUUhK66Zyrq3fq+/+JJvyP76c8LckHrTD/AvmU1UI6z6ybUAxO6voDAZRt90M9URUBYrmXT/z6kJB8tePatb/YvriG6Asqvn4AfceTns/GoVNi/4BSQcbmTj8t9jkCCXLGLfaLD4oPg7yVRnJZBUBdlb1lCyYzWrvz+SlZeOYdV549g9/VTk9ffgveI2ys9eRN6kKWyZNJavThvL6JU7OZwMjttvByBn5d9afp5l+3YA4BgyHKPRiLxW/2DbcM+VrH/sbEpeWNDt78kHt1/GgcUXUV9TRt4H/wQg/N57KY2FjDc2UjXvEvw33s+B3ev18371H969PIuVi8cyZkcTuyc4OGPhdQCcf+29lMQaMeySvPe905mwvpi8iZLzfvAsAGnnXwXA3ndewdVUT8y/3qM0TjLv4Vfb9WnWlffiMYJ7ux6gs383n88enMn/7pjMZ4/MbWm3+hfXEVMPrssWUphiIKFAr41v/NldpL3yMUOeW0HYfc+w/fRpjM7xsefUOC7/1T8piTUQ9VUZK7+bxVenj0de9yOG/P4/7LrgPLY9s5CGr/7U7f+pUApm2OIbwDpgjBCiUAhxkxDiNiHEbYEmq4B8IA/4M3B7v/VWOaraA1twvmdg21sre/W8vB1fAqAZIOEIOAu2dtlONpQTtnIVsfWSNY/f2m5f6ao38Zig+DtN1J5bz+k/eAKEYPYDf6D0bBen3PUICMEZj75MSZwBe53Aa4bEQhj6hYPwj6KQ78ey6c/v8/WyP2L3gGFU67X1s+95BK8RDKuiSVgbTtJnYSSsDaPeLrjgnl9SnBbB0EJJ8dZVZKwrZH+6gcV3/Y5hI8ayZ9ZIhhcYSN1nIGeUhQsfex2TyYzrputwWQR1sZLCTB8Zuw2UvpfApmWPA/D5r+4gwgm2793O6Vc/iGaAhg1f8OHD1zB+i5P6519C8zgpWfUkIttBYaKZGQuvZd4dz7NvDIz/6jCbVv+LlBJJdUY0YxfcyZCFPtIWWEk/8yqOpFlJOewlf89GRq8rYV+GkcX3v0RFDNhLqjnwtf7Bsm+kkeRKkOvW4zHB7KvvZ+Qtt1F2jpvzHvgLQ+ZcCMDOf/8fXz3xAGlfWxmSZ8DsgcIsjfK5jZTNbaTwDCcHpnkoyvJTkQoHMwwYb76RM5fcRm0YmHNaLz42FukfNHGZEwBYeONDfDMpmoy9RqL+F8HulTWUbXij0+/I4f07Gb25kMgmyQe/fgBbbgFVkTBz4Q003HAZRUMF+VM9GIDNb+hBbsffnmX0TkFkueBQqpGJP/19y/GMRhN1S84hpVQwcoeRA+M1xl1zPcJsB2DmguspiwF7zkHe+cX3SaiR1J87iqjk9Hb9iklIoWiogbiCesp3raX8P8UkfhpG6td2zB+U46mv1NvtLuRwMlxwx69pyEwmuRK+eudPjNhyhB0TzDQu1qg6p4GyFD9HEgyc8cifMZkt1F51CYnVgpQ8A7WxUHRmE+Xnu5AGiWV1FBvffP6Y/nLurR5nW5RSXtXDfgnccbQ2yvGR+8WbhHsgssTVc+M2yvZtIw3YN8LB2Lwmdn34Mqfd2iGjcNWx+9kFpJaCywwjNhRSlb+N2BFTAIg7VElxMsx/9D2whEFcJgBJY04n6f9aa4vDR4xj+Je7Wx77/X4O7VlPVeF+clctZ/JHeXie/QdNFhg1a3FLu6S0LL65dTHugoOkLLgYW3g0hRvWEjN6AmERscip03Hs/IQtS+8l0ymouOZ7CIOer3z3+X9TcmA3ozJPYYrZ0nLMC258CG58qLkjHNq7mSP/7wZcn1eT/cGLjNxSR84oCxdfoeco21MMDNlbR5izjuoIGFYCq35+MYaCPDIrzBy571IMBgMYbCRdfR3y8dfQfvo4BiBq5tlgspDxw9VgNIPBgG/saCL2fMOee24kww0xN/8AgOp4I3FlXgrzcvAJMJ93LuxbzZgcDwfTDJwSk8S4RT+ERT8EYObiW1n/+7+SunY3sfWwfVo0V/1zXeDnVgsF68ERDzHpYI8BQ+c87kiahZRDHrweN2aLFa1CvwAxYtLsljaXL19HXVUJa1/5NaP/vIqv//gkF824CoTQG0jJhidvYbwfSuIlwz7ciFmDg6NsGE0mFt3yGNz8KLWbXmfz/b8kfN1W/H4/Q3ZXcWCYYOH/9nT5+3nu7b9gbXERKQsvZtHp50B4Uss+g9FI2XAbo3e50Ip2kp8umf9g19do6tLjmPhFOZ898yPG1wj23X4RjYdymfzfPax/9/8YdealpJZKvpkZgzAYSJ67GNa8hPbU7xHAaVn1ZJ4yF1KmwilXQ1hcy7EvuutxDs+7iFEZEzlVSNj6GnL7GzRcfysbf/g4tnU+Dnz5TzK+c12XfQsVdafoIFK5dxMASeXgajz6xb626gv1zEzMPROAqq2fwu6322UU8uNHOJhdg09A7g2LiHDCl09/D/x+yooPklLmpzY1AoZMagnmwTAYDGRMOINT51/L5c++Rf6ZPiwaFGf4GHFa+9sfzr37aS74zb+ZfM6VZM2Yz7l3P82p8/WyxszL9JwiM0+QO9zCwmtbhzFarA7Ssk7D1CaYd9ERho+dTvn1S0gpFZQ9ptf9E37QepyaEYnE14JZA+fDP+ZwkiD1w0NkbjezY+Ywzrl5aUvbGZc/xP4pZqIbCVwLuFffEZsBUakAnHKp/kGRechPzjgrsy/RX4MnKYL4Wog6VElFLJx902M0WfT/rHXprUGkmdURScVwM7H1UBwPc3/1eutOWxSMngepp+oBqItgDqCNHUVkE3z1tn4bibGmniYrJKWObNcuMjaZJff9lp0TIhm5xcf7v7yWD5/4AZ/8/n6q37qHlB215KabaTw3i+hGCHODHD+29QBCEDXlUlzDNdKLPHz+z1+TUAMNYxO7/dGERcSy6LkVTDn/GohIbv0ACTBOnIhFA4sG1osWYg6L6fI4MTPPxgCM3+ghb7iZRXc+waRrfgRAyVcfseHfz2KQEH7adwCYddFt1DkgsUZyINNP2i0r4LJX4Iy72gXzZsNGn6r/jpmsMP1mxC1riDj1Ciw/vp/YOtj60m+6fY2hogL6YCElWol+6cLqhW1rOo+F7k5zNjZl0Q3U2QUyz8Cq+x/ivUUTcTfWQt0RvJtfIybPTO7oaK6479fkp5iJ2+aibutyNix/DoME+6TpPZzp6IwmM2PPWYy2sIZJk9xYk8YE/dz0zLEUxeu/ztbv33nMfVh05xPkpZtIrIbssVbOXNiaUcXNvQiAXaeEc87iG2i48lLsHshPNXLxi2+3P5AQjLvr11RGQeEIExFRnQPAmClzKY4HrxEy72m97mFJSwcgo9BHTZwBe1gkRSlGAGJnnN1lv21TJlEeI3FfMIkhw0b0+nWPX3ILACWf6RdGLfUu6sLpFDybzfjN69SFQebrWxj+j08Z+uJ/yX1iNdENwGXXcf6Dr1EYSKSnXtrh52G2EZ0RD4D9uVfxmCBj7pJe97nZ1Et/RIMd9k0ycPb3ux9rfubl9+C0gB+IvvMeDAYD46fOpjQGHAcq8ezYhscEZ155j95Ni5Ujw8z6+3HObMxppx5T/2ZfeAPfTIpgzDYv788bz3vzx/POr2/r+YnHQAX0waKmAGr9+AL//wo3fBL0U0VNLR4jDBs1icJRCQwvgoRiAyPz/Xz4i+/i/+r3bKuyEVsPMRfr9Vrv1dcSWwdf/PUJmrauQzPAzCs739zTWxnn3szEyCZsadO6DSbdqVg0n60z05l/2c3HfH6DwcCwnz1B9hgTYx74Vbt9515xNxu+N49Zv3kHgItve5Rtd3yXzBeWY7WHdTrW2OnzkPd+j9H3PNXt+RovX0DuZacyeXZrQEudOrfle09SBADu6ZMoStSDUldmXf1z0i5LZc6tzwb9WtsaP+N8KiPBWqSP4nHU+2gM7z48pKePpH7pT9l68Sgarklk78IYGm1GChMtLLrhR1gckZhvv5WdF2SSOfGMTs9PGn82ZTGSyCZJYYaPsWcs7uIswUkfM5WGuy5m0s/+isHUfRU5LCKK3CnRfHN6LLMvvLFle0lGFKmFkqQDjRweaiA6trWkE3PN99lxzlDO++HLx9w/gJlP/pX9I4xY3BKrS+Lz9K4sGiwhj9Nwmo6mTZsm1YpFIbTj33x07y/wYGVouYd9E6K44l/r9SFm9hgIbzPu31UH/71Pr6me/TPeXjKR+BKN2RuyKTm0h8PfrGfiOVfw2fzphDv9DD+nivw1cZh9gsmfr8PuiMTv97P6nFOIbNRockj8wsC8tV3XQHvti2ch7XQYfnpojjfANFUdYfc55xDuhL3XTOaihztffOwPKxdOIKLGx1lfZ7Pu1LEUpVu59D/bg36+z6fh0zxYrI4e2zbt+5y1S29kxDYLxedpnP18bq8/wEPl7d/dR9af9AvQ289K4aoXPz4h/QiWEGKLlHJaV/tO2BJ0Smi58r8mqlqQNy4RE4VEFdeD5kH+7XycxnB2plyHV4OY5CRG7vkDtup9+oWys36KvcFHQ7j+nyl5+DiSh48DoO6Gm0l7+k8UfxBLlCYRf3wMuyMS0DNZbrqJ2F/+idg6wfYZsaF7MbPvDd2xBiBHzBAq4iXhhwVpbbL1/taUFEnmgWrKig4Q2QiHonoOzG0ZjSaMxuBCiiNjBpMyGtllkqRnTjxhwRzgzGvupeTPqzD5IeE7F56wfoSCKrkMEpW5X+pjydPSaEgwM6Tcj3PPh/x3q4mc13xEPfoK8U+8gvGup9j8eiOvlI7H31gB1QcIa5A4w82djnnZjT9iV0Y44S44cMdVTJp7abv9866+m/wU/UKj7bS5x+FVfksIQVOKldI4ydgZC47bac3pIzBI+PIfT2EAREwIP6Q7MlmRCeNZkFmJPXNW/50nCAmJKRweaqTJCrMvOvZy3clABfTBwFlNRckRABLHTUAMjceiwUdLl5K5w0xuZjj159fBBdXknh+J02Zm5tpqVu1JxJP/FZEN4Im0d3no015cRu5jD3LRD5Z22mcwGIh78KfkZYRz9tV39etL/LaZOf8spi90YY8b1nPjEEmdfg4Avq16KdSalNqv54sdr58vddKcfj1PMKIeWMqRu6/Hau/dXyUnG1VyGQwOb6Sy0cIQIPOU6RxqOAirihmd42Z3lplL31yPae97YLQwdswCNM3L29fOY9TuEvZ99gYWH8iY6C4PnZ6eSXp698MQZ867AuZd0T+v61ss5eLHoelHx7UUMXnu5WSbnyElX79tODo9q1/PFz7rVgiPwDTstH49TzBmzbv8RHchJFSGPhgUrKOp3oxmgGFjTiVzytnUOaAoSZJyww8wmYww/iLIWghCYDJbSLzkMqxeOLRzLwDmxKEn+EUo7Vgj9IvWx/OU9jDK4iAmMK9P2riZ/XvCsDh9THc3Y+OV3lPv5CAgC9bjq7VQGmvGbLExZNQUks+r4JTZ1cxY0PWdaTMvvA6nBSKz9Rp4xLBRx7PLykmqLsEG6BNTpY1Wi48NNCqgD3SaG1m0lYgaqE3UR6CYY4YxJMKKZdQ5GKydx0cDWO3h5I+IIC5wQ+nQrGO7aUIZXLQh+vDWunAwWY5yZ61yUlIBfaA7sp3SJj8JNRLjiMAFNCGw3PAuUZcc/SYT/+mtN3yMnND55g/l2ycyazJAyzBWZWBRAX2gK1jHlt2x+AVMuanNXYSpp+rzXhzF7Gvuwi/0uUbsYeH93FFlIBh/9mUAuMLVeImBSAX0AW7LZ++RmWtkw3fGt5vQPxhDUjPJT7VQGa3+8yq64WOmsXcCyHEZJ7oryjFQ/5MHML+mUbP6CM4ImHj3r3t+Qhem/WU5Xo8zxD1TBiwhuOiNbfoUv8qAE1SGLoSYL4TYK4TIE0I81MX+4UKIT4QQO4UQnwoh+veOBAWAygNbGVoGO8YnMn1M+jEdY8jwMaSNmhzajikDm9kGBuOJ7oVyDIJZscgIvAAsAMYBVwkhxnVo9hvgNSnlJOAx4Fco/a6qQJ8MyxSfiNGgLmIpyrddMBn6dCBPSpkvpfQAy4COkxePA9YEvl/bxX6lH5QFVjCPSE45wT1RFOVkEExATwEOt3lcGNjW1g7gksD3FwMRQojOM/orIVVXUgSAIyn9xHZEUZSTQqhGudwPzBFCbAPmAEWAr2MjIcQtQojNQojN5eXlITr1t5e7Un8PY4d3rIApivJtFExALwLaTvmWGtjWQkp5REp5iZRyCvCzwLaajgeSUr4spZwmpZyWkJDQcbfSS/6aOvzAkBGnnOiuKIpyEggmoG8CRgkhMoQQFuBKYGXbBkKIeCFE87F+AvwttN1UuiIanDTaITm+H+etVhRlwOgxoEspNeBOYDWQDSyXUu4WQjwmhGheCHAusFcIkQskAU/0U3+VNkyNHhrtEG5VtxMoihLkjUVSylXAqg7blrb5fgWwIrRdU3picWq47AJxApfvUhTl5KFu/R/A7E0Sl139CBVF0aloMIA5nOBxqClOFUXRqYA+0NSXgpR4XU2EOUFz2E50jxRFOUmogD6QVB9C/m485LxPVcEuDICMiDjRvVIU5SShhkcMIOXb32fb2njs4W8QPvZcbIAhSg1ZVBRFpzL0AeTQtjUMKxaU7cim8rA+j4s1Xi3urCiKTgX0k4GUUFvYYzOtLA8Aa7mLhrIjAIQnp/dnzxRFGUBUQD8Z5K6G5yZB9aHu2zRVodVVARBbDlpFKQAJ6WoeF0VRdCqgnwzKdoP0QVl2920KN+H26j+umHowFJfgB4aNnnJ8+qgoyklPBfSTQU1gduKq/O7bHN6A19N6DTv+kJtGO8RFx/Rz5xRFGShUQD8Z1BTo/3YM6H4/7FwODWVQsAGXz4E/sCuhBhodYFArFSmKEqCGLZ4MarvJ0A9vgLduBksE+Nxo3jTqHT58RklsPbjsKpgritJKZegnmpTIbkoueTlbWbUxmYOWdPB58HuMNFoNVCTon8Muu1rIV1GUViqgn2hNlRyo87Nq3RDqKw+Dz9uyK3/nBjLyDXzmOx3uy8XogkabiabkKAC8DvOJ6rWiKCchFdBPtJoCDtXayTgkKGoytdbTAV+9PkzRXVUNEUnYnR6abBZMIzIB8IepeVwURWmlAvqJVlOAP3Cl06UZoepAyy5fYx0AokYP7A6XhtNuY/jpF+AXQIwa4aIoSqugAroQYr4QYq8QIk8I8VAX+9OEEGuFENuEEDuFEAtD39VBqvYwPp9+cdPlM7SvozsbATDX1gIQ5vThttuZNvdScm+cyem3P3Pcu6soysmrx1EuQggj8AJwHlAIbBJCrJRS7mnT7OfoS9O9KIQYh766UXo/9HfwqTmM5tdr4W6fpV1Al243AI76Bnw+DYcbNEcYBqOBix985YR0V1GUk1cwGfp0IE9KmS+l9ADLgCUd2kggMvB9FHAkdF0chJzVsPcD/fvaw2hY9c0iol1AF24PABENLuqqijEAvvDIjkdTFEUBggvoKcDhNo8LA9vaegT4f0KIQvTs/K6uDiSEuEUIsVkIsbm8vPwYujtI7HwT3rgSCrfoGbrUM3SX39Ya0L1O8OjF9chGLzVlRfr2iKgT0WNFUQaAUF0UvQr4u5QyFVgI/EMI0enYUsqXpZTTpJTTEhISQnTqAcjToP+7+W9QW4AvENC9PjNUHwS/DxpKQdNr61GNkooS/TPVHKnmP1cUpWvBBPQiYFibx6mBbW3dBCwHkFKuA2xAfCg6OChpem2cb94EVy0+v36DkOY1gt+r3zlaX4Lw6AHdKKEsdxcAlhj1tiqK0rVgAvomYJQQIkMIYQGuBFZ2aFMAnAMghBiLHtC/PTWVwxvhvR/CaxfBmid6bq+59H99emCXPv3H4PcGbuUvy4b6Egze1lv7G/flAhAWkxS6fiuKMqj0GNCllBpwJ7AayEYfzbJbCPGYEGJxoNl9wM1CiB3AG8ANUkrZX50+6Xz5HGx7HYq2wo5lPbfX3GCLgpRpAMjAsEU8gDDox2koxegVeAN39xsL9AUwohLUCkWKonQtqMm5pJSr0C92tt22tM33e4BZoe3aAIkKJFwAACAASURBVOLzQPJEGDIJclb13F5zgckGs36oZ/b+QGnF44WELDiyDZInYvJCaZSR1Cof0SX6WPS4xNT+fCWKogxg6k7RUPBrYDCByd5aTjkazQ0mK4xbDA/mIzR9NIvF7YGhU/SA3lCK2SMojnQAkFjlxWOCuBh1UVRRlK6pgB4KLQHdGmRAD2ToAEJg9PkAsLg1PaA3VUDhZixeqAkPx20Ckx/qbYJIm5rxWFGUrqmAHgp+HxiMYLbr5Re/7+jtmzP0AGMgQ7d6fDB0qr6xYi82D/hsNmrC9B9To9VIhE3NsKgoStdUQA+Fthk6tA5L7E7bDB0wafoHgM3jg6TxYDDh8YNFA+lwUB2YJrfBasJmVj8yRVG6pqJDKLStoUPPZRfN3SGg6xm6zeMHsw0Sx9HoCwxvsTuotettG20WhFCrFCmK0jUV0EOhU4beU0B3tSu5mHzNAR38fj8MnUJjYGy6tIVRFxYGgNNq7XwsRVGUABXQQ6FtDR30eViOpmOGHgjoJj943U2QMpUmLZChO8JxhkUA4LQ7Qt51RVEGDxXQQ+GYauhtMnSt9R6shppyGDUPZ9xEAAyOSNyB+Vs8KqArinIUKqCHQqcaem8zdEnzzaKNtRUQOYT60Zfq+8Ki8EUn6k8LU1PnKorSPRXQQ6HXGbqzXYZu9knq7XpEd9ZXA9BUVwOANTIGU6x+u78MU1PnKorSPRXQQ8Hv0wP6MdfQJXV2vWbuCgRyd51+q78tPIawMWfz+qmj8Jxycej7rijKoKECeij4Nf2i6DHW0M0a1Fv1seZNtfqC0N76egDsUXHERobxz2G3EhEzJPR9VxRl0FD3kYdCb2rofr9+N2kgQ/f5NEx+qLNZACfOQIauNegBPSI6EYuw6N+r2/4VRTkKFSFCoTmgmwNlFO9RxqEH5kBvztA97iYA6qw2oBZXfR0AsqkJzQARYRE40Ovr4SqgK4pyFCpChILfB0Zza138aDcWNe8LtPU4GwGos+rZfXOphaYmXBaw28xYjHplLMqu5nFRFKV7QdXQhRDzhRB7hRB5QoiHutj/OyHE9sBXrhCiJvRdPYm11NCDCegdMnSXHtAbrOH67kCpRThdOM0G7GYj44dG8qtLJnLuWLVakaIo3esxQxdCGIEXgPOAQmCTEGJlYFELAKSU97RpfxcwpR/6evJqqaEfS4auLxjttYahGcDfqJdgjC43Tose0IUQXDU9rd+6ryjK4BBMhj4dyJNS5kspPcAyYMlR2l+Fvgzdt0fHcehHq6F3ytD1AC4sFlwWkE79gqrJ5cFpNuKwGPut24qiDC7BBPQU4HCbx4WBbZ0IIYYDGcCabvbfIoTYLITYXF4+SNaQ9vsBqQd0IfTMuxcZujcQ0A0WK06zAeHU91tcGk0WEzYV0BVFCVKox6FfCayQUna5woOU8mUp5TQp5bSEhIQQn/oE8Wv6v4ZA4O0xoLfP0L2BUS5Giw2XxYCxOaC7NZxmE3azCuiKogQnmIBeBAxr8zg1sK0rV/JtLLeAnqFDrzN0zaU/NtjsOM1GjC4PoK9e5DKbMRvVvV+KogQnmGixCRglhMgQQljQg/bKjo2EEFlADLAutF08yfm9+r/NAd1sC7KGHii5BDJ0s1UP6Ga3fjybx4/brOY/VxQleD0GdCmlBtwJrAaygeVSyt1CiMeEEIvbNL0SWCallF0dZ9BqXj+01xl6oOTi0i+CWuwOnGYTFrcPv9+PzQ0uiwroiqIEL6gbi6SUq4BVHbYt7fD4kdB1awA55hp680VRPaDb7A6cJjNWdyOupjqMErwWW3dHURRF6UQVaPvqmGvo7TN0q92B02TB6vHrc6IDXota0EJRlOCpgN5XHQN6jzX0jhdF9YzdbLXjNluweSSNNfqQTs0W1i9dVhRlcFIBva96naF3HLboCjx04LHYMPugvvwIoC8QrSiKEiwV0PvqmC+K6hm63x3I0G1heCz6BF0V+3YBIO0Roe+voiiDlgrofXWsF0WN+hznfk9zycXRchE06g/LqA4TuIae1i9dVhRlcFIBva+OpYZusunTBAC+QMnFYgtHs+olFrfVwDPzf4A5OrXfuq0oyuCjAnpfdaqh24++BJ3mbrf8nPToNxJZ7WGUDZnOltExJL/yZwpsWdgt6sejKErwVMToq041dOvRl6BrztADpMeD1whmkwl/zGhWLvwtGRPOwOnxqXlcFEXpFRXQ+6pjDd1s19cM9fu7bt8hQ8fr1QO6UWAzG3B6fUgpcXpVQFcUpXdUQO+rTiWXQLDu7sJohwxdeLx4jQKT0YDdYsTl9eHW9A8DNXWuoii9oQJ6X3VVQ4ejBPSOGbqGZgSzQWAzGXF6fTg9ehlHZeiKovSGCuh91dcM3duaodssRlxeP06vHtDVakWKovSGCuh91XJRtE0NHcDbzYVRzd0+oGsaXqMBk1HP0F1eX0tAt6kMXVGUXlABva+6zdC7GbqoudqVXAxeH16jwGwwYLcY9ICuSi6KohwDFdD7qtsaepsMvaEcDn4Z2N4+QzdoPrQ2Gbrml9S79GPaVclFUZReCCqgCyHmCyH2CiHyhBAPddPmciHEHiHEbiHEv0LbzZNYEBn6R8/fzns/vhF8WtcZusGA2ShaAvhXefr0uUmRaj50RVGC1+MCF0III/ACcB5QCGwSQqyUUu5p02YU8BNglpSyWgiR2F8dPul0vLGoixp63Y48xu8wUV2UQ0yHDN2o+fQausGANVBi+fMX+cwdk8DoJDU5l6IowQsmQ58O5Ekp86WUHmAZsKRDm5uBF6SU1QBSyrLQdvMk1mlyrs4ZurlRX/i5KHdLpwzd6PO3XBRtrpm7NT/3nz+m//uuKMqgEkxATwEOt3lcGNjW1mhgtBDiKyHEeiHE/FB18KTXEtDN+r9d1NDtDfqNQpWHcjrV0E1eP16jEbPRgM2s/zgWTkxmQkpU//ddUZRBJag1RYM8zihgLpAKfC6EmCilrGnbSAhxC3ALQFpaWohOfYIFUUMPb9D/bSwpAH8XGbrBgMkgGJ0UQXqcg/tUdq4oyjEIJkMvAoa1eZwa2NZWIbBSSumVUh4ActEDfDtSypellNOklNMSEhKOtc8nlx5q6FpDJZGN+iZ3Zak+z0vbDF2TeI1GTEYDo5Mi+PSBs8hMCD9evVcUZRAJJqBvAkYJITKEEBbgSmBlhzbvoGfnCCHi0Usw+SHs58mrhxp6ce4mjFLfJGtq27cBTD6J12DEbBTHo7eKogxiPQZ0KaUG3AmsBrKB5VLK3UKIx4QQiwPNVgOVQog9wFrgASllZX91+qTSwzj04txtLU0N9e2XnwMwa3pANxnULQGKovRNUDV0KeUqYFWHbUvbfC+BewNf3y491NCrDu8jAvALMDd627cBTD7wGk0qQ1cUpc9UWthXvg4BXQg9Aw/U0J0lxQCUxAosTYHnNC8Q7fdj9oFmNCGECuiKovSNCuh91aaG7vf78fv9gYWi9QzdX12DT0BZrAV7UyBoBzJ0r1uP8JohVIONFEX5NlMBva/8GggjCMGqH13KxwunBwK6nqEb6pzUhUFThIOIJvBLWjJ0t1Mfz6iZVEBXFKXvVEDvK78GBhN+v5/Y9XsZdrCRSp+lJUO31HupDxN4wqOwaFCvGVoydI9LH8/oM1pOWPcVRRk8VEDvq0BAP7DrK2Lq9DtCc8oNLTV0e6OfpnAjnih9epsKr7klQ/e4AiUXFdAVRQkBFdD7yu8Dg4n8T97VHwqoLpH6nC1SEtkATocFLU6/M7bGY2oJ6N5AQPebzCem74qiDCqqeNtXfg0MRjwbN1MVZaQxzoGtqAE0F00VBYS5wB0RhjFRv3G20d0moAcuiqqSi6IooaAy9L7ya/iEicScMqonDMM7cRTJJZKGxgbKczcA4I2KJXJoJgAul7G15OLUa+jSpAK6oih9pwJ6X/k19taaCHdKwmbOJG7GLIwSsovqqTiwCwAZm0ps4jA0A3hdrRdFW0suKqAritJ3gy6g1xblsOqOubjrq47PCf0+Ckr1t3Hs+Zcxds7F+IHyIhe1hQcAMA8ZTWy4nbowkC4DG/+3gtUXzsBZXa4fos2do4qiKMdq0AX09c/eQcYnpWxb8ezxOaFfQxZJyhLMJA8fR1TcEEqSDNjyfTRs1zP08IxTiXaYqXcYMDUacD7/Cmn76qhc8SYAUgV0RVFCYHAFdGcNcqc+s++RnL3H5ZRej4ekIkn9hOEt24pHxjGkDEZtd+G0QGLKSKLtFhrsJoYdNpBY7qXJCunbS/UnmNTaoYqi9N2gGuVSveY5Ugv12+vlkdLjcs7cI+XYPRA5/fSWbcunPMmL0TuYTjaHPGE8HmkjymGm2BbJeFlB8VAb8pL5DP3jO3pfzSqgK4rSd4MnQ/e62L7qDYwSGmwQVlJ3XE5beLAagFFz9ZmEpZTsL2ugxJrB2+YFbA37DvHhViKsJqps+qLPtttu5PQbfkyDXf/wESqgK4oSAoMnoO/4F02HJNVhgtIRGnEVbn2irH7mO9RARTQMyZgAQEmdi0aPj5tnj2iZEjfGYcFgEHydvpCP5p3GzEvvxBEeTdnZE/WDWCP7vZ+Kogx+g6Pk4vfh/vw5hhQYWT8yjsyoQsKdJiqL80lIGdlvp/X5NBIKNEpHtb6NeWX6hFtzRifgl5KPs0uxmPTPTU/8BPJSZmEILGYxZ+kL/Iwn8Eel91sfFUX59ggqQxdCzBdC7BVC5AkhHupi/w1CiHIhxPbA1/dD39Wj2PMuX+ypw+6BLYlZxER4ACj4Zl2/njZv6xrCXRA2rLVk0hzQMxPD+MmCLD760Xda9kXZzdQ0eVoeh0fFk516kVqtSFGUkOgxkgghjMALwAJgHHCVEGJcF03/LaWcHPj6S4j72T0p+fzvv2TIV3b2Z0awI/JMUh2B1YKyd/TrqQu++BCAkWmtJZO8sgYibSYSwq0IITAZW9/iaIeZWqe33TE0n8SkVitSFCUEgim5TAfypJT5AEKIZcASYE9/dqw7H//+Aez/+oDpX2zGbLHxzVvPEPtfJ0VpVkrv+ROuj/NItnopsYA7fz9FedvZe/ONmN1ayPsS26hRFQljou0t2/aXNzAyMbzLFYii7WbyyxvbbfP6/ZiNKkNXFKXvggnoKcDhNo8LgRldtPuuEOI7QC5wj5TycMcGQohbgFsA0tLSet9bwBQeQWytjwM7v2T0tHM5vPZ/DAdO+/M/+WIrmG0ODEBFrBFTQQnbfvUThpW5ODwtFUKcCNcCkfHVGNpMrpVX1sjZWQldto92WNqVXCCQoRtUhq4oSt+F6qLoe8AbUkq3EOJW4FXg7I6NpJQvAy8DTJs2TR7LiVKnzsbLGxzZpgd0Ciopj4Xxw8azf/UGhsdHQQXUxVkZsa8Ga24NB+aNZ9FzK/ry+rr3pzkt64nWNnmpaHAzMjG8y6ZRdjN1Lg3N528pxXh9sl1ZRlEU5VgFE0mKgGFtHqcGtrWQUlZKKd2Bh38BTg1N9zpLnzALtwkadn0DQHSxi4ZEAUKwv7yBzMQI3JhxR9uwe8BjghkPPNVf3dHnQzfq85nnldcDkJnQdUAfFusA4FBVU8s2ze9vGd6oKIrSF8EE9E3AKCFEhhDCAlwJrGzbQAgxpM3DxUB26LrYnslsoXyoA3PeYcqL8oipB3OyjXqXl9I6N5mJYXgxYwjUtY9cMLVfhy42z4cOsL9Mr493l6GPTtK37yttaNmml1xUhq4oSt/1WHKRUmpCiDuB1YAR+JuUcrcQ4jFgs5RyJXC3EGIxoAFVwA392GfcmUMZ8nUe+Rs/JhKIG5bYcrExMyEcTZiJS4zj0LUjmXPnL/uzKy1L0AHklTdgMRlIjXF02bQ5c88rqweSAfD6VIauKEpoBFVDl1KuAlZ12La0zfc/AX4S2q51zz5uPI61eez/4D0igczRY/gkMP57ZGI4XmHBKnzM+dlL/d+ZtgG9rIER8WEYu7nIGWY1kRJtZ19Zmwzdr4YtKooSGgPyb/3kKfpEWEPX51MZCTFDMtlzpA672Uh6XBg+gxnh8/RwlBAJrCkKekDP7Kbc0mx0Uji5gZKLlBKfX5VcFEUJjQEZSUZMPQufALsH6hL8EDmUPcW1ZA2JwGgQ+IQFg/94BXS9hu7y+jhc3cTIbi6INhuVFMH+8gZ8fonXpw/0USUXRVFCYUAGdLsjkvKkwKIQsV5keBJ7jtQxboh+x6bfYMHo9x7lCCEUKLkcqGhEyu4viDYbmRiOR/NzuKoJLTB5mBq2qChKKAzYSNI4IgmA2CgPJTKWOpfG+KFRAPiMxzND94LB1DKHS08BfVRgf25pfUuGrm4sUhQlFAZsQLdNnoxmgBGRTnbX60MUxw3VM3RpsGCWx7eGnlfWgBCQER921OajkvQ50feVNaD59Axd3fqvKEooDNjpc+fc9ihHIstJLP6Yb8o0DALGBIKlNFox+WuPT0cCNfS88gaGxTiwmY1HbR5uNTE0ykZeWQOaP5Chqxq6oighMGBTQ7PFxnCbGyKHsPtIHSMSwrFb9GAqTRbMeFsy4H4VqKHvL2vosdzSbGRSBPvK6vE2Z+hqlIuiKCEwsCNJfQlEJJNdXMf4oW1W/TFaseDF6fX1fx/8Gn5hJL+iMeiAPioxnLyyBjxa80VRlaEritJ3Az6ge+yJFNU4W0a4AGCyYkHr/4Du94P0U+eWeDR/j0MWm41OCsfl9XOwUr+7VY1yURQlFAZuJPH7oaGEMhEHtF4QBTCYrFiFF5enn0suUv/AqHTq58lMPPoF0WYjE/Vaf3axPpmXWY1yURQlBAZuQG+qAL/GfqeeFU8IDFkEEObjVHLx64tmVDTp5xmZEBHU05pLM3uK6wCVoSuKEhoDN5LUHQFgc5WN8UMjiQlrXWTCYLIdp5KLHtDLGzXiw61EOcxBPS3KbiYp0kr2keaArjJ0RVH6bsAOW6S+BIB15RZmnRHfbpfBbNMzdM/xCehVTj9psfYeGrc3OimCL/MqADXKRRl8vF4vhYWFuFyuE92VActms5GamorZHFyiCAM6oBcDcESL4q6R7QO60WLFJPy43e6unhk6fv0Do9YtSYi39uqpIxPD+WKfHtBVhq4MNoWFhURERJCent7l+rrK0UkpqayspLCwkIyMjKCfN3BTQ49+q73TGMZp6THtdpnMNgBcLmf/9iGQode5JfHhvQvooxJb6+1qci5lsHG5XMTFxalgfoyEEMTFxfX6L5ygAroQYr4QYq8QIk8I8dBR2n1XCCGFENN61Ytj4dVf6NhhiTgs7f/QMFn0gO52H6eA7pEkRPQyoCe1DnFU0+cqg5EK5n1zLO9fj5FECGEEXgAWAOOAq4QQ47poFwH8ENjQ614cA6ezAU0amDkyudM+o1UP6F53P9fvAgFdk8ZjyNDbBHSVoSuKEgLBpIbTgTwpZb6U0gMsA5Z00e5x4GnguFwFKamoxoWFWaMSOu2zWPULlP0f0PUauoah1wE92mFpyerV5FyKEnpGo5HJkye3fB08eJDKykrOOusswsPDufPOO090F0MumIuiKcDhNo8LgRltGwghpgLDpJT/FUI80N2BhBC3ALcApKWl9b63bTibGnBhYUxy57Hf5kDJRfMcn5KLD2OvSy6gZ+nl9W41fa6i9AO73c727dvbbWtsbOTxxx9n165d7Nq16wT1rP/0eZSLEMIAPEsQC0NLKV8GXgaYNm2a7Mt5/R4nLizEWTrPbmgMXBT1HqeArmEkoZcZOuhDF7/eX6kydGVQe/S93ewJ3HMRKuOGRvKLC8f3+nlhYWGceeaZ5OXlhbQ/J4tgAnoRMKzN49TAtmYRwATg00ARPxlYKYRYLKXcHKqOdiS9TrzC2vWFA5MeXH2e/h622JyhG4iPsPTQuLMJKVEYDYJw68AdPaooJyun08nkyZMByMjI4O233z7BPep/wUSSTcAoIUQGeiC/Eri6eaeUshZoGQguhPgUuL8/gzmA0Jx4Dd1kxUY9uGqe43NR1GQydxppE4yLp6QweVh0u7tcFWWwOZZMOhS6KrkMdj3+rS+l1IA7gdVANrBcSrlbCPGYEGJxf3ewO0Jz4esuoJv0kovPe3wuiobZbcf0dKNBBD3lrqIoSk+CSiullKuAVR22Le2m7dy+d6tnRp8bzdhNIDXpGa/s94CuZ+jh9t7XzxVFUUJtwBZvTX4XXmtM1zuNeoD1a8enhh7u6N08LoqinDjp6enU1dXh8Xh45513+Oijjxg3rtOtNQPSAA7obqSpuwxdD+jSG1xAzympY0iUnSh78JPgAC0BPSLs2EouiqL0n4aGhi63Hzx48Ph25DgakOPlpJRYpBth6SYzbg7ovp4Deq3Ty4V/+JKFv/+CbQXVveqHpnkBiFQZuqIoJ4EBGdCbPD5suDGYHV03CJRcCKLksrekHq9PUt3k4fI/rWNtTlnQ/ahv1Gv0USpDVxTlJDAgA3qdy4sNL0Zrdxm6flFUBBHQc0r0Gx7euv0M4sKsLN98uIdntOlHU3NAVxm6oign3oAM6LVNHmx4MFq7WcOzOUP3e3o8Vk5JPVF2M2OSIpg1Mp4NB6rw+4O7ibXeqQf06PBu/lJQFEU5jgZkQK9raMQgJGZrN4E0UEM3aEEE9OI6xiRHIIRgxohYqho97Cvr+mJKs1XfFLN6dwn1gQw9Nlxl6IqinHgDMqA3NNQDYLF1k6EbjPiEEYP0HDXb9vsluaUNjA1M8HX6iDgANhyo7PY5Pr/k4Xd28cNl2yisqAUgRmXoiqKcBAZkQG9qagTA5ugmoAN+gwULGi6t+3VFi2qcNLg1xiRHApAaYycl2s76/O4D+vbD1VQ2enB5/WzML9f7YVW37ivKyaZ5+twJEyZw2WWX0dTU1OdjLl26lI8//rjb/S+99BKvvfZan89zrAZmQG/USyJW+9EDuhXPUReKzi7WL4hmDdEz9Oayy/r8KqSUHKxopM7lbfecj7PLMBkEd58zChOBYxsG7HB+RRm0mudy2bVrFxaLhZdeeqndfk3Ten3Mxx57jHPPPbfb/bfddhvXXXddr48bKgMyErma9IBuc3Q/D0pzhu70dh/Q95bopZsxSa1zqs8cEcdbW4v45X+z+fvXB7l82jB+dcnElv2fZJcyPSOWu88eyZ+3W6ARFdAV5Wg+eAhKvgntMZMnwoKngm4+e/Zsdu7cyaeffsrDDz9MTEwMOTk5ZGdn89BDD/Hpp5/idru54447uPXWWwF4+umn+ec//4nBYGDBggU89dRT3HDDDSxatIhLL72Uhx56iJUrV2IymTj//PP5zW9+wyOPPEJ4eDj3338/27dv57bbbqOpqYnMzEz+9re/ERMTw9y5c5kxYwZr166lpqaGv/71r8yePTskb8uAjERup15yMVq6r11LowWL8FJY7eStrUVcf0Z6pztBc0rqSYt1ENZm+trmOvpfvzyAySDYfrimZV9BZRO5pQ1ccVoaJqOBm84YBv8DDJ3nZFcU5eSgaRoffPAB8+fPB2Dr1q3s2rWLjIwMXn75ZaKioti0aRNut5tZs2Zx/vnnk5OTw7vvvsuGDRtwOBxUVVW1O2ZlZSVvv/02OTk5CCGoqanpdN7rrruOP/zhD8yZM4elS5fy6KOP8txzz7X0aePGjaxatYpHH330qGWc3hiQAd0TCOh0d+s/II1WrGjc/Opm6t36n1Z3nzOqXZuckjqyOqx4lBpjZ9GkIWTEh+HR/PztqwN4ND8Wk4GPs0sBOHdsIgAWEbjgqjJ0ReleLzLpUGo7H/rs2bO56aab+Prrr5k+fToZGRkAfPTRR+zcuZMVK1YAUFtby759+/j444+58cYbcTj0pDE2NrbdsaOiorDZbNx0000sWrSIRYsWtdtfW1tLTU0Nc+bMAeD666/nsssua9l/ySWXAHDqqaeGdCqCARmJPK5AQDd3P1xQmqxY8GI1G0mJsbNiSyF3njUSQ2C5N5fXx4GKRi6YNLTd84QQ/PHqqQC8t+MIXp8kt7SeCSlRfJJTyqjEcIbHBWr3gblcVEBXlJNPd/Ohh4W1XnuTUvKHP/yBefPmtWuzevXqox7bZDKxceNGPvnkE1asWMEf//hH1qxZE3TfrFZ9aLXRaDymWn53BuRFUc0duFp9lAzdbrMzMtbMO3ecwW1zMimoamLDgdY/mzYeqMIvYUpadLfHGDdUH/2yp7iOJo/GpgPVnJWV2NpABXRFGdDmzZvHiy++iNerD37Izc2lsbGR8847j1deeaVlZEzHkktDQwO1tbUsXLiQ3/3ud+zYsaPd/qioKGJiYvjiiy8A+Mc//tGSrfenoCKREGI+8HvACPxFSvlUh/23AXcAPqABuEVKuSfEfW3h8wQCendzuaCvKzoixggxDuLDrUS8a+LNzYc5PVOvkX+eW47FZGBmRly3x0iPC8NhMbLnSB3x4RY8Pj9zRie0NvCrUS6KMpB9//vf5+DBg0ydOhUpJQkJCbzzzjvMnz+f7du3M23aNCwWCwsXLuTJJ59seV59fT1LlizB5XIhpeTZZ5/tdOxXX3215aLoiBEjeOWVV/r99Qgpj36buxDCCOQC5wGF6EvSXdU2YAshIqWUdYHvFwO3SynnH+2406ZNk5s3H9sqdU8+/mN++v/bu/foquorgePfTUIIASGEl5CABOSRgIRHQEBbsIJgKy9pFYeqWJQyUKCtrhF1liNdq52q4ziwTJFamfpqYAHyHMVVSHTGIvIy8kbehhQxgIYGEshjzx/n3OQGkptLvHDuDfuzVlZyHjd33x/cfX/Zv9/5nbJX4Ve7oXlS9Se9OQ4unoNH/wrA0yt28u7242x+ZjjNYhty18sf0eaGWN5+9NaAz3XvH/5GdIMGpLZvxpItueT82wgaRbuDoFm/hf99EZ67fEDEmOvZ3r17SUlJ8TqMiFddO4rINlVNr+78YEouA4GDqnpYVS8Ci4Gx/if4krmrZA557AAAEatJREFUCRDcYih1pCVFzg/RAS65j24Efsvn3p/egeKSchZv/pITBUV8cbKQ73drVfPjXantm7HnxFk++iKfQZ0TKpM5OCUX650bY8JEMNkoEfBfgvA4cFm3VkRmAL8GYoAfhCS6alwoLSOq7ILzURRgUJSomCrL56Z1iGdot9ZkZB9CcAZGv+9fPqlBz/bNeXvTlxReKOWhwTdVPWgJ3RgTRkI2KKqqGaraBXgS+NfqzhGRqSKyVUS25ufn1+l5zhaVEivuolsBBkWJbnTZeuhz7u7B2eISXvxgP22bNapyQVFNUts1q/j5sg+A8jJL6MaYsBFMQs8DOvhtJ7n7arIYGFfdAVX9o6qmq2p669a1946rU1BUQiwXKWsQAw0ChB/VCMqqrraY0q4Z4/smcrGsnO91bY2I01Nn258h/4tqf033G28gqoGQGN+Yzq0uWWqgvNQuKjLGhI1gEvoWoKuIJItIDDARWO1/goj4X7HzI+BA6EKsypfQywPVz6HaHjrA43d1JzG+MWPS3Pnn507Bmtmw6C44fvkgbWzDKO7o3oYf90+q/ADwsZKLMSaM1JqNVLVURH4BfIAzbXGRqu4Wkd8AW1V1NfALERkOlADfAA9frYCduxVdrPkG0T7Rl/fQARLjG/O3OX4l/lNuz7z0IrwxBh5eA0n9qzzmTw9XO6BsCd0YE1aCqqGr6nuq2k1Vu6jqb919z7rJHFWdrao9VbWPqt6hqruvVsBni0poLBeR2nroUTFQWlz7L/Ql9IdWQlQ0bFsUfDBWQzcmrK1cuRIRYd++fV6Hck1E3JWivpKLxARRcim7CLXMs+fUAWdwNTEdkgbC8W3BB2M1dGPCWmZmJrfffjuZmZlX7TnKympe0fVai7juZVm50qRBCQ0CrLQIOD10cJK6e0u6ap0+CAldnAHWpHQ4uB6Kz0Jss5of42MlF2Nq9fzm59l3JrQ95B4JPXhy4JMBzyksLOTjjz8mOzub0aNHM3fuXMrKynjyySdZt24dDRo04LHHHmPmzJls2bKF2bNnc+7cORo1asSGDRtYvnw5W7du5ZVXXgHgnnvu4YknnmDYsGE0bdqUn//856xfv56MjAyysrJYs2YNRUVFDBkyhIULFyIiHDx4kGnTppGfn09UVBRLly5l7ty53HvvvYwb58wdmTRpEvfddx9jx44N9HKCEnHZ6JHbkmF/E5Ba/rjw1dhLLwRO6Ke+gBt7Oz8npQMKf/8MOgdYd+HD3zvPbwndmLC1atUqRo0aRbdu3WjZsiXbtm1j8+bNHD16lJycHKKjozlz5gwXL17k/vvvZ8mSJQwYMICzZ8/SuHHgCsC5c+e49dZbeemllwBITU3l2WefBeDBBx9k7dq1jB49mkmTJjFnzhzGjx9PcXEx5eXlTJkyhZdffplx48ZRUFDAxo0beeONN0LymiMzG5UWQVzNa7AAlUm8moHRyt9zEb45Br0mONuJ7mBo3taaE3pZCWx8BUrOQatultCNqUVtPemrJTMzk9mzZwMwceJEMjMzOXLkCNOmTSM62nnfJiQksHPnTtq1a8eAAQMAaNas9r/Oo6KimDBhQsV2dnY2L7zwAufPn+fMmTP07NmTYcOGkZeXx/jx4wGIjXU6mUOHDmX69Onk5+ezfPlyJkyYUBHPdxWZ2aikOPBVolBZcgk0MPrNEdAyaOnOumzcAlreHLiOnrcNLjp3OiJ/H7RLCz5uY8w1cebMGbKysti5cyciQllZGSJSkbSDER0dTXl5ecV2cXFlLomNjSUqKqpi//Tp09m6dSsdOnTgueeeq3JudR566CHefvttFi9eHNJFuyJuUBRweujBzEOHaueiV/DNcGnlN40+Md3podc0mHr4Q0Bg0Axn23roxoSdZcuW8eCDD3Ls2DGOHj1Kbm4uycnJpKWlsXDhwoo1yM+cOUP37t05ceIEW7ZsAZyVFEtLS+nUqRM5OTmUl5eTm5vL5s2bq30uX/Ju1aoVhYWFFTfLuOGGG0hKSmLlypUAXLhwoWI53smTJ1fcvSg1NTVkrzsyE3pJETQMYh46BC65nHKvf2p5c+W+pHQoPOkk7lcGwt/mVX3MoWxo3xd+8Aw0aRN4+QFjjCcyMzMrSh0+EyZM4MSJE3Ts2JHevXuTlpbGX/7yF2JiYliyZAkzZ84kLS2NESNGUFxczG233UZycjKpqanMmjWLfv36Vftc8fHxPPbYY/Tq1YuRI0dW+SvgrbfeYv78+fTu3ZshQ4bw1VdfAdC2bVtSUlJ45JFHQvq6a10+92r5Lsvn8u8doc8DcPfzNZ+z7z1Y/ABM/QgSOlc/a2XldDi4AZ7YX7kvbzu8dgdIlFOOuel2eOR/nGPFZ+H5TnD7L+HOZ+HE505Pvn2fur0OY+opWz43sPPnz3PLLbewfft2mjdvXuN5V2P53PBTWlR7zzjaraGvmgG/7wCHqrk91KkvqpZbANr2gpim0Kw9dLkTTu6qLL8c/dhJ8p3vcLbbpVkyN8ZckfXr15OSksLMmTMDJvO6iLwCcHmZU0apbVA0toXz/R8noFEz2P4mdPG75F/VKbn0urfq46Jj4NH1Tjll97twaAOc/Ts0T4TD2c5dkjoMDO1rMsZcN4YPH86xY8euyu+OvB667+YWtSX0xH7w8Fr45U5Imwj734figsrj/zgBxd86Uw8v1SYFmrSEtj2d7ZPuSgaHP4SbhgSe126MMR6JvITum4ZY2ywXEUj+HsQ0gd73O4/bu6by+OGPnO833Vbz72jjjj6f3AUFeU6JxlduMcaYMBN5Cb3Ed4PoK5hdktjfGRjdsaRy3+FsiGvl1Mxr0jgemneAr/c45wN0sYRujAlPEZjQ3R56w1rWcvEn4vTSj/yf09NWdconnYcGvkkGOGWXk7ud6YpN2lT22o0xJsxEXkIv9d0g+grnf/e+z/m+6Q/w9V5nrnkw5ZO2PZ1Sy+Fs6DzM+XAwxoS9qKgo+vTpQ69evRg9ejTffvttSH9/p06dOHXqFABNmzYN6e+uq8hL6BU99CtM6AmdIe0B2PwafPa2sy+Y8kmbVGcRrvOnrdxiTARp3LgxOTk57Nq1i4SEBDIyMrwO6aoLatqiiIwC5uHcsehPqvr7S47/GngUKAXygZ+p6tWZl1NRQ7+CkovPHU/BrmWwKcNZv6V5Uu2P8a+xdx525c9pzHXuq9/9jgt7Q7t8bqOUHtz49NNBnz948GB27NgBwKFDh5gxYwb5+fnExcXx2muv0aNHD06ePMm0adM4fPgwAAsWLGDIkCGMGzeO3NxciouLmT17NlOnTg3pawmlWhO6iEQBGcAI4DiwRURWq+oev9M+A9JV9byI/DPwAnD/1Qi4cpZLHS65j+8IA6fCJ68En5xb3uws9JXQ2bnYyBgTUcrKytiwYQNTpkwBYOrUqbz66qt07dqVTz/9lOnTp5OVlcWsWbMYOnQoK1asoKysjMLCQgAWLVpEQkICRUVFDBgwgAkTJtCyZS2rvXokmB76QOCgqh4GEJHFwFigIqGrarbf+ZuAn4YyyCqCnYdek+897lyyn/ZAcOdHRUP/R6BNj7o9nzHXuSvpSYdSUVERffr0IS8vj5SUFEaMGEFhYSEbN27kJz/5ScV5Fy44C/hlZWXx5ptvAk793XcV5/z581mxYgUAubm5HDhwIKITeiKQ67d9HLg1wPlTgPerOyAiU4GpAB07dgwyxEuU1HFQ1CcuASavvbLH/PCFuj2XMcYzvhr6+fPnGTlyJBkZGUyePJn4+HhycnKC+h0ffvgh69ev55NPPiEuLo5hw4bVujSul0I6KCoiPwXSgRerO66qf1TVdFVNb926dd2exDfLpS41dGPMdScuLo758+fz0ksvERcXR3JyMkuXLgVAVfn8888BuPPOO1mwYAHglGkKCgooKCigRYsWxMXFsW/fPjZt2uTZ6whGMAk9D+jgt53k7qtCRIYDzwBjVDXAIuTfUV1nuRhjrlt9+/ald+/eZGZm8s477/D666+TlpZGz549WbVqFQDz5s0jOzubW265hf79+7Nnzx5GjRpFaWkpKSkpzJkzh0GDBnn8SgILpuSyBegqIsk4iXwi8E/+J4hIX2AhMEpVvw55lP4SkiFljPXQjTEB+QY1fdasqVz6Y926dZed37Zt24rk7u/996utIHP06NEan8srtSZ0VS0VkV8AH+BMW1ykqrtF5DfAVlVdjVNiaQosFefCmy9VdcxVibjHj5wvY4wxVQQ1D11V3wPeu2Tfs34/Dw9xXMYYY65Q5F0paoyJCF7dDa2+qEv7WUI3xoRcbGwsp0+ftqReR6rK6dOniY29sskfkXfHImNM2EtKSuL48ePk5+d7HUrEio2NJSkpiOVJ/FhCN8aEXMOGDUlOTvY6jOuOlVyMMaaesIRujDH1hCV0Y4ypJ8SrUWgRyQfqumZ6K+BUCMO5GizG0LAYQyPcYwz3+CB8YrxJVatdDMuzhP5diMhWVU33Oo5ALMbQsBhDI9xjDPf4IDJitJKLMcbUE5bQjTGmnojUhP5HrwMIgsUYGhZjaIR7jOEeH0RAjBFZQzfGGHO5SO2hG2OMuYQldGOMqSciLqGLyCgR2S8iB0VkjtfxAIhIBxHJFpE9IrJbRGa7+xNE5K8icsD93sLjOKNE5DMRWetuJ4vIp25bLhGRGI/jixeRZSKyT0T2isjgMGzDX7n/xrtEJFNEYr1uRxFZJCJfi8guv33Vtps45rux7hCRfh7G+KL7b71DRFaISLzfsafcGPeLyEivYvQ79riIqIi0crc9acfaRFRCF5EoIAO4G0gFHhCRVG+jAqAUeFxVU4FBwAw3rjnABlXtCmxwt700G9jrt/088LKq3gx8A0zxJKpK84B1qtoDSMOJNWzaUEQSgVlAuqr2wrmD10S8b8c/A6Mu2VdTu90NdHW/pgILPIzxr0AvVe0NfAE8BeC+dyYCPd3H/MF973sRIyLSAbgL+NJvt1ftGJiqRswXMBj4wG/7KeApr+OqJs5VwAhgP9DO3dcO2O9hTEk4b+wfAGsBwbnqLbq6tvUgvubAEdyBer/94dSGiUAukICzUulaYGQ4tCPQCdhVW7vh3Pv3gerOu9YxXnJsPPCO+3OV9zXO7S8HexUjsAyng3EUaOV1Owb6iqgeOpVvKJ/j7r6wISKdgL7Ap0BbVT3hHvoKaOtRWAD/BfwLUO5utwS+VdVSd9vrtkwG8oH/dstCfxKRJoRRG6pqHvAfOD21E0ABsI3wakefmtotXN9DPwN8d2MOmxhFZCyQp6qfX3IobGL0F2kJPayJSFNgOfBLVT3rf0ydj3FP5oiKyD3A16q6zYvnD1I00A9YoKp9gXNcUl7xsg0B3Dr0WJwPn/ZAE6r5Ez3ceN1utRGRZ3DKlu94HYs/EYkDngaere3ccBFpCT0P6OC3neTu85yINMRJ5u+o6rvu7pMi0s493g742qPwbgPGiMhRYDFO2WUeEC8ivpuceN2Wx4Hjqvqpu70MJ8GHSxsCDAeOqGq+qpYA7+K0bTi1o09N7RZW7yERmQzcA0xyP3ggfGLsgvPh/bn73kkCtovIjYRPjFVEWkLfAnR1ZxXE4AycrPY4JkREgNeBvar6n36HVgMPuz8/jFNbv+ZU9SlVTVLVTjhtlqWqk4Bs4Mdexwegql8BuSLS3d11J7CHMGlD15fAIBGJc//NfTGGTTv6qandVgMPubM0BgEFfqWZa0pERuGUAceo6nm/Q6uBiSLSSESScQYeN1/r+FR1p6q2UdVO7nvnONDP/b8aNu1YhddF/DoMWvwQZ0T8EPCM1/G4Md2O8yftDiDH/fohTp16A3AAWA8khEGsw4C17s+dcd4oB4GlQCOPY+sDbHXbcSXQItzaEJgL7AN2AW8BjbxuRyATp6ZfgpN0ptTUbjiD4Rnu+2cnzowdr2I8iFOH9r1nXvU7/xk3xv3A3V7FeMnxo1QOinrSjrV92aX/xhhTT0RaycUYY0wNLKEbY0w9YQndGGPqCUvoxhhTT1hCN8aYesISujHG1BOW0I0xpp74fxndwikkEmnzAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Testing\n",
        "As we can see in the paper no one of this models has accuracies higher than 60 and the result we got here is very close to the paper"
      ],
      "metadata": {
        "id": "rzq5I4qhN-4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Hybrid CNN-RNN model"
      ],
      "metadata": {
        "id": "KxiSj98ibUig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  preds = model_hyb(test_dataset.input.to(device))\n",
        "  target = test_dataset.target.to(device)\n",
        "  ac = multiclass_accuracy(preds, target, num_classes=2).item()\n",
        "  pr = multiclass_precision(preds, target, num_classes=2).item()\n",
        "  f1 = multiclass_f1_score(preds, target, num_classes=2).item()\n",
        "  re = multiclass_recall(preds, target, num_classes=2).item()\n",
        "  print(f\"Accuracy: {ac:.3f}, F1: {f1:.3f}, Precision: {pr:.3f}, Recall: {re:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YZqi5AJ5JLr",
        "outputId": "29bc6afe-8380-4a92-b511-540412667f2c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.548, F1: 0.548, Precision: 0.549, Recall: 0.548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test RNN model"
      ],
      "metadata": {
        "id": "l1TtQPmXbnEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  preds = model_rnn(test_dataset.input.to(device))\n",
        "  target = test_dataset.target.to(device)\n",
        "  ac = multiclass_accuracy(preds, target, num_classes=2).item()\n",
        "  pr = multiclass_precision(preds, target, num_classes=2).item()\n",
        "  f1 = multiclass_f1_score(preds, target, num_classes=2).item()\n",
        "  re = multiclass_recall(preds, target, num_classes=2).item()\n",
        "  print(f\"Accuracy: {ac:.3f}, F1: {f1:.3f}, Precision: {pr:.3f}, Recall: {re:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8KSN70dbMZ5",
        "outputId": "644fc0c0-dc3f-4e58-f4d3-b0eb256224b1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.495, F1: 0.494, Precision: 0.495, Recall: 0.495\n"
          ]
        }
      ]
    }
  ]
}